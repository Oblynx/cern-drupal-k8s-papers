
@book{adamatzkyAdvancesPhysarumMachines2016,
  title = {Advances in {{Physarum Machines}}: {{Sensing}} and {{Computing}} with {{Slime Mould}}},
  shorttitle = {Advances in {{Physarum Machines}}},
  editor = {Adamatzky, Andrew},
  year = 2016,
  publisher = {{Springer International Publishing}},
  url = {https://www.springer.com/gp/book/9783319266619},
  urldate = {2019-05-29},
  abstract = {This book is devoted to Slime mould Physarum polycephalum, which is a large single cell capable for distributed sensing, concurrent information processing, parallel computation and decentralized actuation. The ease of culturing and experimenting with Physarum makes this slime mould an ideal substrate for real-world implementations of unconventional sensing and computing devices The book is a treatise of theoretical and experimental laboratory studies on sensing and computing properties of slime mould, and on the development of mathematical and logical theories of Physarum behavior. It is shown how to make logical gates and circuits, electronic devices (memristors, diodes, transistors, wires, chemical and tactile sensors) with the slime mould. The book demonstrates how to modify properties of Physarum computing circuits with functional nano-particles and polymers, to interface the slime mould with field-programmable arrays, and to use Physarum as a controller of microbial fuel cells. A unique multi-agent model of slime is shown to serve well as a software slime mould capable for solving problems of computational geometry and graph optimization. The multiagent model is complemented by cellular automata models with parallel accelerations. Presented mathematical models inspired by Physarum include non-quantum implementation of Shor's factorization, structural learning, computation of shortest path tree on dynamic graphs, supply chain network design, p-adic computing and syllogistic reasoning. The book is a unique composition of vibrant and lavishly illustrated essays which will inspire scientists, engineers and artists to exploit natural phenomena in designs of future and emergent computing and sensing devices. It is a 'bible' of experimental computing with spatially extended living substrates, it spanstopics from biology of slime mould, to bio-sensing, to unconventional computing devices and robotics, non-classical logics and music and arts.},
  file = {/home/oblivion/Zotero/storage/S47A7G7X/9783319266619.html},
  isbn = {978-3-319-26661-9},
  langid = {english},
  series = {Emergence, {{Complexity}} and {{Computation}}}
}

@software{aglassingerPygount,
  title = {Pygount},
  author = {Aglassinger, Thomas},
  url = {https://github.com/roskakori/pygount},
  urldate = {2019-06-04}
}

@software{aglassingerPygount2019,
  title = {Pygount},
  author = {Aglassinger, Thomas},
  date = {2019-05-10T17:16:22Z},
  origdate = {2013-04-13T13:02:29Z},
  url = {https://github.com/roskakori/pygount},
  urldate = {2019-06-10}
}

@inproceedings{alvarezManagingCERNBatch2020,
  title = {Managing the {{CERN Batch System}} with {{Kubernetes}}},
  author = {Alvarez, L. F. and Datskova, Olga and Jones, B. and McCance, G.},
  year = 2020,
  doi = {10.1051/epjconf/202024507048},
  abstract = {The CERN Batch Service faces many challenges in order to get ready for the computing demands of future LHC runs. These challenges require that we look at all potential resources, assessing how efficiently we use them and that we explore different alternatives to exploit opportunistic resources in our infrastructure as well as outside of the CERN computing centre. Several projects, like BEER, Helix Nebula Science Cloud and the new OCRE project, have proven our ability to run batch workloads on a wide range of non-traditional resources. However, the challenge is not only to obtain the raw compute resources needed but how to define an operational model that is cost and time efficient, scalable and flexible enough to adapt to a heterogeneous infrastructure. In order to tackle both the provisioning and operational challenges it was decided to use Kubernetes. By using Kubernetes we benefit from a de-facto standard in containerised environments, available in nearly all cloud providers and surrounded by a vibrant ecosystem of open-source projects. Leveraging Kubernetes’ built-in functionality, and other open-source tools such as Helm, Terraform and GitLab CI, we have deployed a first cluster prototype which we discuss in detail. The effort has simplified many of the existing operational procedures we currently have, but has also made us rethink established procedures and assumptions that were only valid in a VM-based cloud environment. This contribution presents how we have adopted Kubernetes into the CERN Batch Service, the impact its adoption has in daily operations, a comparison on resource usage efficiency and the experience so far evolving our infrastructure towards this model.},
  file = {/home/oblivion/Zotero/storage/APPD7Z7R/Alvarez et al. - 2020 - Managing the CERN Batch System with Kubernetes.pdf}
}

@article{alvarezManagingCERNBatch2020a,
  title = {Managing the {{CERN Batch System}} with {{Kubernetes}}},
  author = {Alvarez, Luis Fernandez and Datskova, Olga and Jones, Ben and McCance, Gavin},
  year = 2020,
  journaltitle = {EPJ Web of Conferences},
  shortjournal = {EPJ Web Conf.},
  volume = {245},
  pages = {07048},
  publisher = {{EDP Sciences}},
  issn = {2100-014X},
  doi = {10.1051/epjconf/202024507048},
  abstract = {The CERN Batch Service faces many challenges in order to get ready for the computing demands of future LHC runs. These challenges require that we look at all potential resources, assessing how efficiently we use them and that we explore different alternatives to exploit opportunistic resources in our infrastructure as well as outside of the CERN computing centre. Several projects, like BEER, Helix Nebula Science Cloud and the new OCRE project, have proven our ability to run batch workloads on a wide range of non-traditional resources. However, the challenge is not only to obtain the raw compute resources needed but how to define an operational model that is cost and time efficient, scalable and flexible enough to adapt to a heterogeneous infrastructure. In order to tackle both the provisioning and operational challenges it was decided to use Kubernetes. By using Kubernetes we benefit from a de-facto standard in containerised environments, available in nearly all cloud providers and surrounded by a vibrant ecosystem of open-source projects. Leveraging Kubernetes’ built-in functionality, and other open-source tools such as Helm, Terraform and GitLab CI, we have deployed a first cluster prototype which we discuss in detail. The effort has simplified many of the existing operational procedures we currently have, but has also made us rethink established procedures and assumptions that were only valid in a VM-based cloud environment. This contribution presents how we have adopted Kubernetes into the CERN Batch Service, the impact its adoption has in daily operations, a comparison on resource usage efficiency and the experience so far evolving our infrastructure towards this model.},
  file = {/home/oblivion/Zotero/storage/HRAAV769/Alvarez et al. - 2020 - Managing the CERN Batch System with Kubernetes.pdf;/home/oblivion/Zotero/storage/5HRUGF8R/epjconf_chep2020_07048.html},
  langid = {english}
}

@article{andersonMoreDifferent1972,
  title = {More {{Is Different}}},
  author = {Anderson, P. W.},
  year = 1972,
  journaltitle = {Science},
  volume = {177},
  pages = {393--396},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.177.4047.393},
  eprint = {17796623},
  eprinttype = {pmid},
  file = {/home/oblivion/Zotero/storage/EXTFNM5P/393.html},
  langid = {english},
  number = {4047}
}

@article{asselinAnomalyDetectionWeb2016,
  title = {Anomaly Detection for Web Server Log Reduction: {{A}} Simple yet Efficient Crawling Based Approach},
  shorttitle = {Anomaly Detection for Web Server Log Reduction},
  author = {Asselin, E. and Melchor, C. A. and Jakllari, G.},
  year = 2016,
  journaltitle = {2016 IEEE Conference on Communications and Network Security (CNS)},
  doi = {10.1109/CNS.2016.7860553},
  abstract = {Offering a secured shared hosting environment for web applications is not a trivial task. In addition to a well secured system configuration, up-to-date shared hosting are still exposed to security threats by compromised web applications that serve as spam relay, distributed denial of service actors, phishing page hosting and drive-by download page hosting to name a few. As a result, the availability of the server could suffer from a bad IP address reputation and thus, blocked access to all accounts in the server, not only the compromised account. The emergence of web application firewalls (WAF) manages to close the gap by thoroughly analysing HTTP requests in search of known vulnerabilities. However, as any misuse type mechanism, it falls short at discovering zero-day attacks or already compromised environment. In this paper, an anomaly detection model is proposed as a very helpful tool to start building an efficient intrusion detection system adapted to a specific web application or to assist a forensic analysis. The learning phase does not need past activities nor prior knowledge of the web application and its underlying architecture, making it a very simple yet powerful tool for reducing the access log entries for further analysis.}
}

@inproceedings{astekinIncrementalAnalysisLargeScale2019,
  title = {Incremental {{Analysis}} of {{Large}}-{{Scale System Logs}} for {{Anomaly Detection}}},
  booktitle = {2019 {{IEEE International Conference}} on {{Big Data}} ({{Big Data}})},
  author = {Astekin, M. and Özcan, S. and Sözer, H.},
  year = 2019,
  pages = {2119--2127},
  doi = {10.1109/BigData47090.2019.9006593},
  abstract = {Anomalies during system execution can be detected by automated analysis of logs generated by the system. However, large scale systems can generate tens of millions of lines of logs within days. Centralized implementations of traditional machine learning algorithms are not scalable for such data. Therefore, we recently introduced a distributed log analysis framework for anomaly detection. In this paper, we introduce an extension of this framework, which can detect anomalies earlier via incremental analysis instead of the existing offline analysis approach. In the extended version, we periodically process the log data that is accumulated so far. We conducted controlled experiments based on a benchmark dataset to evaluate the effectiveness of this approach. We repeated our experiments with various periods that determine the frequency of analysis as well as the size of the data processed each time. Results showed that our online analysis can improve anomaly detection time significantly while keeping the accuracy level same as that is obtained with the offline approach. The only exceptional case, where the accuracy is compromised, rarely occurs when the analysis is triggered before all the log data associated with a particular session of events are collected.},
  eventtitle = {2019 {{IEEE International Conference}} on {{Big Data}} ({{Big Data}})},
  keywords = {anomaly detection,Anomaly detection,big data,Big Data,Distributed databases,distributed systems,Feature extraction,Large-scale systems,log analysis,machine learning,Machine learning,parallel processing,Tools}
}

@inproceedings{banekWhyLSSTScience2019,
  title = {Why Is the {{LSST Science Platform}} Built on {{Kubernetes}}?},
  author = {Banek, Christine and Thornton, Adam and Economou, Frossie and Fausti, Angelo and Krughoff, K. Simon and Sick, Jonathan},
  year = 2019,
  url = {http://arxiv.org/abs/1911.06404},
  urldate = {2021-02-26},
  abstract = {LSST has chosen Kubernetes as the platform for deploying and operating the LSST Science Platform. We first present the background reasoning behind this decision, including both instrument-agnostic as well as LSST-specific requirements. We then discuss the basic principles of Kubernetes and Helm, and how they are used as the deployment base for the LSST Science Platform. Furthermore, we provide an example of how an external group may use these publicly available software resources to deploy their own instance of the LSST Science Platform, and customize it to their needs. Finally, we discuss how more astronomy software can follow these patterns to gain similar benefits.},
  archiveprefix = {arXiv},
  eprint = {1911.06404},
  eprinttype = {arxiv},
  file = {/home/oblivion/Zotero/storage/YCJXFYKE/Banek et al. - 2019 - Why is the LSST Science Platform built on Kubernet.pdf;/home/oblivion/Zotero/storage/Q29X4EDA/1911.html},
  keywords = {Astrophysics - Instrumentation and Methods for Astrophysics},
  primaryclass = {astro-ph}
}

@online{banekWhyLSSTScience2019a,
  title = {Why Is the {{LSST Science Platform}} Built on {{Kubernetes}}?},
  author = {Banek, Christine and Thornton, Adam and Economou, Frossie and Fausti, Angelo and Krughoff, K. Simon and Sick, Jonathan},
  year = 2019,
  url = {http://arxiv.org/abs/1911.06404},
  urldate = {2021-04-29},
  abstract = {LSST has chosen Kubernetes as the platform for deploying and operating the LSST Science Platform. We first present the background reasoning behind this decision, including both instrument-agnostic as well as LSST-specific requirements. We then discuss the basic principles of Kubernetes and Helm, and how they are used as the deployment base for the LSST Science Platform. Furthermore, we provide an example of how an external group may use these publicly available software resources to deploy their own instance of the LSST Science Platform, and customize it to their needs. Finally, we discuss how more astronomy software can follow these patterns to gain similar benefits.},
  archiveprefix = {arXiv},
  eprint = {1911.06404},
  eprinttype = {arxiv},
  file = {/home/oblivion/Zotero/storage/WA3EBRU2/Banek et al. - 2019 - Why is the LSST Science Platform built on Kubernet.pdf;/home/oblivion/Zotero/storage/NB6TQYD3/1911.html},
  keywords = {Astrophysics - Instrumentation and Methods for Astrophysics},
  primaryclass = {astro-ph}
}

@inproceedings{beltreEnablingHPCWorkloads2019,
  title = {Enabling {{HPC Workloads}} on {{Cloud Infrastructure Using Kubernetes Container Orchestration Mechanisms}}},
  booktitle = {2019 {{IEEE}}/{{ACM International Workshop}} on {{Containers}} and {{New Orchestration Paradigms}} for {{Isolated Environments}} in {{HPC}} ({{CANOPIE}}-{{HPC}})},
  author = {Beltre, A. and Saha, P. and Govindaraju, M. and Younge, Andrew and Grant, R.},
  year = 2019,
  doi = {10.1109/CANOPIE-HPC49598.2019.00007},
  abstract = {Containers offer a broad array of benefits, including a consistent lightweight runtime environment through OS-level virtualization, as well as low overhead to maintain and scale applications with high efficiency. Moreover, containers are known to package and deploy applications consistently across varying infrastructures. Container orchestrators manage a large number of containers for microservices based cloud applications. However, the use of such service orchestration frameworks towards HPC workloads remains relatively unexplored. In this paper we study the potential use of Kubernetes on HPC infrastructure for use by the scientific community. We directly compare both its features and performance against Docker Swarm and bare metal execution of HPC applications. Herein, we detail the configurations required for Kubernetes to operate with containerized MPI applications, specifically accounting for operations such as (1) underlying device access, (2) inter-container communication across different hosts, and (3) configuration limitations. This evaluation quantifies the performance difference between representative MPI workloads running both on bare metal and containerized orchestration frameworks with Kubernetes, operating over both Ethernet and InfiniBand interconnects. Our results show that Kubernetes and Docker Swarm can achieve near bare metal performance over RDMA communication when high performance transports are enabled. Our results also show that Kubernetes presents overheads for several HPC applications over TCP/IP protocol. However, Docker Swarm's throughput is near bare metal performance for the same applications.}
}

@article{benedekIntelligenceCreativityCognitive2014,
  title = {Intelligence, Creativity, and Cognitive Control: {{The}} Common and Differential Involvement of Executive Functions in Intelligence and Creativity},
  shorttitle = {Intelligence, Creativity, and Cognitive Control},
  author = {Benedek, Mathias and Jauk, Emanuel and Sommer, Markus and Arendasy, Martin and Neubauer, Aljoscha C.},
  year = 2014,
  journaltitle = {Intelligence},
  shortjournal = {Intelligence},
  volume = {46},
  pages = {73--83},
  issn = {0160-2896},
  doi = {10.1016/j.intell.2014.05.007},
  abstract = {Intelligence and creativity are known to be correlated constructs suggesting that they share a common cognitive basis. The present study assessed three specific executive abilities – updating, shifting, and inhibition – and examined their common and differential relations to fluid intelligence and creativity (i.e., divergent thinking ability) within a latent variable model approach. Additionally, it was tested whether the correlation of fluid intelligence and creativity can be explained by a common executive involvement. As expected, fluid intelligence was strongly predicted by updating, but not by shifting or inhibition. Creativity was predicted by updating and inhibition, but not by shifting. Moreover, updating (and the personality factor openness) was found to explain a relevant part of the shared variance between intelligence and creativity. The findings provide direct support for the executive involvement in creative thought and shed further light on the functional relationship between intelligence and creativity.},
  file = {/home/oblivion/Zotero/storage/AD5KNEFL/Benedek et al. - 2014 - Intelligence, creativity, and cognitive control T.pdf;/home/oblivion/Zotero/storage/VPHFQE9S/S0160289614000798.html},
  keywords = {Creativity,Divergent thinking,Executive control,Intelligence,no,Working memory}
}

@online{bengioBiologicallyPlausibleDeep2015,
  title = {Towards {{Biologically Plausible Deep Learning}}},
  author = {Bengio, Yoshua and Lee, Dong-Hyun and Bornschein, Jorg and Mesnard, Thomas and Lin, Zhouhan},
  year = 2015,
  url = {http://arxiv.org/abs/1502.04156},
  urldate = {2019-05-28},
  abstract = {Neuroscientists have long criticised deep learning algorithms as incompatible with current knowledge of neurobiology. We explore more biologically plausible versions of deep representation learning, focusing here mostly on unsupervised learning but developing a learning mechanism that could account for supervised, unsupervised and reinforcement learning. The starting point is that the basic learning rule believed to govern synaptic weight updates (Spike-Timing-Dependent Plasticity) arises out of a simple update rule that makes a lot of sense from a machine learning point of view and can be interpreted as gradient descent on some objective function so long as the neuronal dynamics push firing rates towards better values of the objective function (be it supervised, unsupervised, or reward-driven). The second main idea is that this corresponds to a form of the variational EM algorithm, i.e., with approximate rather than exact posteriors, implemented by neural dynamics. Another contribution of this paper is that the gradients required for updating the hidden states in the above variational interpretation can be estimated using an approximation that only requires propagating activations forward and backward, with pairs of layers learning to form a denoising auto-encoder. Finally, we extend the theory about the probabilistic interpretation of auto-encoders to justify improved sampling schemes based on the generative interpretation of denoising auto-encoders, and we validate all these ideas on generative learning tasks.},
  archiveprefix = {arXiv},
  eprint = {1502.04156},
  eprinttype = {arxiv},
  file = {/home/oblivion/Zotero/storage/GXPTB24L/Bengio et al. - 2015 - Towards Biologically Plausible Deep Learning.pdf;/home/oblivion/Zotero/storage/73N3QEBB/1502.html},
  keywords = {*,Computer Science - Machine Learning},
  primaryclass = {cs}
}

@article{bergerAnomalyDetectionUser2017,
  title = {Anomaly Detection in User Behavior of Websites Using {{Hierarchical Temporal Memories}} : {{Using Machine Learning}} to Detect Unusual Behavior from Users of a Web Service to Quickly Detect Possible Security Hazards.},
  shorttitle = {Anomaly Detection in User Behavior of Websites Using {{Hierarchical Temporal Memories}}},
  author = {Berger, Victor},
  year = 2017,
  journaltitle = {undefined},
  url = {/paper/Anomaly-detection-in-user-behavior-of-websites-%3A-to-Berger/894f370ce30ce070ccc33701e5e2409882314f13},
  urldate = {2021-04-22},
  abstract = {This Master\&\#39;s Thesis focuses on the recent Cortical Learn-ing Algorithm (CLA), designed for temporal anomaly detection. It is here applied to the problem of anomaly detec-tion in user behavior of w ...},
  file = {/home/oblivion/Zotero/storage/LZXG64Z9/894f370ce30ce070ccc33701e5e2409882314f13.html},
  langid = {english}
}

@article{bezansonJuliaFreshApproach2017,
  title = {Julia: {{A Fresh Approach}} to {{Numerical Computing}}},
  shorttitle = {Julia},
  author = {Bezanson, J. and Edelman, A. and Karpinski, S. and Shah, V.},
  year = 2017,
  journaltitle = {SIAM Review},
  shortjournal = {SIAM Rev.},
  volume = {59},
  pages = {65--98},
  issn = {0036-1445},
  doi = {10.1137/141000671},
  abstract = {Bridging cultures that have often been distant, Julia combines expertise from the diverse fields of computer science and computational science to create a new approach to numerical  computing. Julia is  designed to be easy and fast and questions notions generally held to be “laws of nature"  by practitioners of numerical computing: \textbackslash beginlist \textbackslash item  High-level dynamic programs have to be slow. \textbackslash item  One must prototype in one language and then rewrite in another language for speed or deployment. \textbackslash item There are parts of a system appropriate for the programmer, and other parts that are best left untouched as they have been built by the experts. \textbackslash endlist We introduce the  Julia programming language and its design---a  dance between specialization and abstraction. Specialization allows for custom treatment. Multiple dispatch,  a  technique from computer science, picks  the right algorithm for the right circumstance. Abstraction, which is what good computation is really about, recognizes what remains the same after differences are stripped away. Abstractions in mathematics are captured as code through another technique from computer science, generic programming. Julia shows that  one can achieve machine performance without sacrificing human convenience.},
  file = {/home/oblivion/Zotero/storage/2P9U3Z9S/Bezanson et al. - 2017 - Julia A Fresh Approach to Numerical Computing.pdf;/home/oblivion/Zotero/storage/2X6Y8837/141000671.html},
  number = {1}
}

@online{billaudellePortingHTMModels2015,
  title = {Porting {{HTM Models}} to the {{Heidelberg Neuromorphic Computing Platform}}},
  author = {Billaudelle, Sebastian and Ahmad, Subutai},
  year = 2015,
  url = {http://arxiv.org/abs/1505.02142},
  urldate = {2019-06-02},
  abstract = {Hierarchical Temporal Memory (HTM) is a computational theory of machine intelligence based on a detailed study of the neocortex. The Heidelberg Neuromorphic Computing Platform, developed as part of the Human Brain Project (HBP), is a mixed-signal (analog and digital) large-scale platform for modeling networks of spiking neurons. In this paper we present the first effort in porting HTM networks to this platform. We describe a framework for simulating key HTM operations using spiking network models. We then describe specific spatial pooling and temporal memory implementations, as well as simulations demonstrating that the fundamental properties are maintained. We discuss issues in implementing the full set of plasticity rules using Spike-Timing Dependent Plasticity (STDP), and rough place and route calculations. Although further work is required, our initial studies indicate that it should be possible to run large-scale HTM networks (including plasticity rules) efficiently on the Heidelberg platform. More generally the exercise of porting high level HTM algorithms to biophysical neuron models promises to be a fruitful area of investigation for future studies.},
  archiveprefix = {arXiv},
  eprint = {1505.02142},
  eprinttype = {arxiv},
  file = {/home/oblivion/Zotero/storage/U4V625LP/Billaudelle and Ahmad - 2015 - Porting HTM Models to the Heidelberg Neuromorphic .pdf;/home/oblivion/Zotero/storage/3IHPY7BQ/1505.html},
  keywords = {Computer Science - Neural and Evolutionary Computing,Quantitative Biology - Neurons and Cognition},
  primaryclass = {cs, q-bio}
}

@incollection{bradingSymmetrySymmetryBreaking2017,
  title = {Symmetry and {{Symmetry Breaking}}},
  booktitle = {The {{Stanford Encyclopedia}} of {{Philosophy}}},
  author = {Brading, Katherine and Castellani, Elena and Teh, Nicholas},
  editor = {Zalta, Edward N.},
  year = 2017,
  edition = {Winter 2017},
  publisher = {{Metaphysics Research Lab, Stanford University}},
  url = {https://plato.stanford.edu/archives/win2017/entries/symmetry-breaking/},
  urldate = {2019-05-29},
  abstract = {Symmetry considerations dominate modern fundamental physics, both inquantum theory and in relativity. Philosophers are now beginning todevote increasing attention to such issues as the significance ofgauge symmetry, quantum particle identity in the light of permutationsymmetry, how to make sense of parity violation, the role of symmetrybreaking, the empirical status of symmetry principles, and so forth.These issues relate directly to traditional problems in the philosophyof science, including the status of the laws of nature, therelationships between mathematics, physical theory, and the world, andthe extent to which mathematics suggests new physics., This entry begins with a brief description of the historical roots andemergence of the concept of symmetry that is at work in modernscience. It then turns to the application of this concept to physics,distinguishing between two different uses of symmetry: symmetryprinciples versus symmetry arguments. It mentions the differentvarieties of physical symmetries, outlining the ways in which theywere introduced into physics. Then, stepping back from the details ofthe various symmetries, it makes some remarks of a general natureconcerning the status and significance of symmetries in physics.},
  file = {/home/oblivion/Zotero/storage/DQWEKRQ3/symmetry-breaking.html}
}

@misc{builtwithptyltdOpenSourceUsage,
  title = {Open {{Source Usage Distribution}} in the {{Top}} 10k {{Sites}}},
  howpublished = "\url{https://trends.builtwith.com/cms/open-source/traffic/Top-10k}",
  year = 2021,
  note = "Accessed: 2021-02-21",
}

@book{burnsKubernetesRunningDive2019,
  title = {Kubernetes: {{Up}} and {{Running}}: {{Dive}} into the {{Future}} of {{Infrastructure}}},
  shorttitle = {Kubernetes},
  author = {Burns, Brendan and Beda, Joe and Hightower, Kelsey},
  year = 2019,
  publisher = {{"O'Reilly Media, Inc."}},
  abstract = {Kubernetes radically changes the way applications are built and deployed in the cloud. Since its introduction in 2014, this container orchestrator has become one of the largest and most popular open source projects in the world. The updated edition of this practical book shows developers and ops personnel how Kubernetes and container technology can help you achieve new levels of velocity, agility, reliability, and efficiency.Kelsey Hightower, Brendan Burns, and Joe Beda—who’ve worked on Kubernetes at Google and beyond—explain how this system fits into the lifecycle of a distributed application. You’ll learn how to use tools and APIs to automate scalable distributed systems, whether it’s for online services, machine learning applications, or a cluster of Raspberry Pi computers.Create a simple cluster to learn how Kubernetes worksDive into the details of deploying an application using KubernetesLearn specialized objects in Kubernetes, such as DaemonSets, jobs, ConfigMaps, and secretsExplore deployments that tie together the lifecycle of a complete applicationGet practical examples of how to develop and deploy real-world applications in Kubernetes},
  isbn = {978-1-4920-4650-9},
  keywords = {Computers / Cloud Computing,Computers / Programming / Open Source,Computers / Software Development & Engineering / Systems Analysis & Design,Computers / System Administration / General,Computers / Systems Architecture / Distributed Systems & Computing,Computers / Web / Web Programming,Computers / Web / Web Services & APIs},
  langid = {english},
  pagetotal = {278}
}

@online{buytaertStateDrupalPresentation,
  title = {State of {{Drupal}} Presentation ({{October}} 2019)},
  author = {Buytaert, Dries},
  url = {https://dri.es/state-of-drupal-presentation-october-2019},
  urldate = {2021-02-21},
  abstract = {DrupalCon Amsterdam Driesnote presentation},
  file = {/home/oblivion/Zotero/storage/9ETWZ3GR/state-of-drupal-presentation-october-2019.html},
  langid = {english}
}

@book{cern.genevaRealCostsOpen2019,
  title = {The Real Costs of {{Open Source Sustainability}}},
  editor = {Brasseur, VM},
  year = 2019,
  eventtitle = {The Real Costs of {{Open Source Sustainability}}},
  keywords = {CERN Computing Seminar,Event},
  pagetotal = {1},
  series = {{{CERN Computing Seminar}}}
}

@online{chazelleNaturalAlgorithmsInfluence,
  title = {Natural {{Algorithms}} and {{Influence Systems}}},
  author = {Chazelle, Bernard},
  url = {https://cacm.acm.org/magazines/2012/12/157889-natural-algorithms-and-influence-systems/abstract},
  urldate = {2019-05-28},
  abstract = {Algorithms lay the grounds for numerical simulations and, crucially, provide a powerful framework for their analysis. The new area of natural algorithms may reprise in the life sciences the role differential equations have long played in the physical sciences.},
  file = {/home/oblivion/Zotero/storage/QCJ5LGX5/abstract.html},
  langid = {english}
}

@article{chazelleNaturalAlgorithmsInfluence2012,
  title = {Natural Algorithms and Influence Systems},
  author = {Chazelle, Bernard},
  year = 2012,
  journaltitle = {Communications of the ACM},
  volume = {55},
  pages = {101--110},
  issn = {0001-0782},
  doi = {10.1145/2380656.2380679},
  file = {/home/oblivion/Zotero/storage/Q4AYNLY2/Chazelle - 2012 - Natural algorithms and influence systems.pdf;/home/oblivion/Zotero/storage/H9UABH9L/citation.html},
  number = {12}
}

@online{chazelleNaturalAlgorithmsInfluencea,
  title = {Natural {{Algorithms}} and {{Influence Systems}}},
  author = {Chazelle, Bernard},
  url = {https://cacm.acm.org/magazines/2012/12/157889-natural-algorithms-and-influence-systems/abstract},
  urldate = {2019-06-20},
  abstract = {Algorithms lay the grounds for numerical simulations and, crucially, provide a powerful framework for their analysis. The new area of natural algorithms may reprise in the life sciences the role differential equations have long played in the physical sciences.},
  file = {/home/oblivion/Zotero/storage/PKB5FGNH/abstract.html},
  langid = {english}
}

@article{chielBrainHasBody1997,
  title = {The Brain Has a Body: Adaptive Behavior Emerges from Interactions of Nervous System, Body and Environment},
  shorttitle = {The Brain Has a Body},
  author = {Chiel, Hillel J. and Beer, Randall D.},
  year = 1997,
  journaltitle = {Trends in Neurosciences},
  shortjournal = {Trends in Neurosciences},
  volume = {20},
  pages = {553--557},
  issn = {0166-2236},
  doi = {10.1016/S0166-2236(97)01149-1},
  abstract = {Studies of mechanisms of adaptive behavior generally focus on neurons and circuits. But adaptive behavior also depends on interactions among the nervous system, body and environment: sensory preprocessing and motor post-processing filter inputs to and outputs from the nervous system; co-evolution and co-development of nervous system and periphery create matching and complementarity between them; body structure creates constraints and opportunities for neural control; and continuous feedback between nervous system, body and environment are essential for normal behavior. This broader view of adaptive behavior has been a major underpinning of ecological psychology and has influenced behavior-based robotics. Computational neuroethology, which jointly models neural control and periphery of animals, is a promising methodology for understanding adaptive behavior.},
  file = {/home/oblivion/Zotero/storage/VWS5ITFV/S0166223697011491.html},
  keywords = {adaptive behavior,behavior based robotics,biomechanics,computational neuroethology,coupled systems,dynamics,ecological psychology},
  number = {12}
}

@online{ComputationCellsTissues,
  title = {Computation in {{Cells}} and {{Tissues}}},
  url = {https://blackwells.co.uk/bookshop/product/Computation-in-Cells-and-Tissues-by-Ray-Paton/9783642055690},
  urldate = {2019-05-29},
  abstract = {The field of biologically inspired computation has coexisted with mainstream computing since the 1930s, and the pioneers in this area include Warren McCulloch, Walter Pitts, Robert Rosen, Otto Schmitt, Alan Turing, John von Neumann and Norbert Wiener. Ideas arising out of studies of biology have permeated algorithmics, automata theory, artificial intelligence, graphics, information systems and software design. Within this context, the biomolecular, cellular and tissue levels of biological organisation have had a considerable inspirational impact on the development of computational ideas. Such innovations include neural computing, systolic arrays, genetic and immune algorithms, cellular automata, artificial tissues, DNA computing and protein memories. With the rapid growth in biological knowledge there remains a vast source of ideas yet to be tapped. This includes developments associated with biomolecular, genomic, enzymic, metabolic, signalling and developmental systems and the various impacts on distributed, adaptive, hybrid and emergent computation. This multidisciplinary book brings together a collection of chapters by biologists, computer scientists, engineers and mathematicians who were drawn together to examine the ways in which the interdisciplinary displacement of concepts and ideas could develop new insights into emerging computing paradigms. Funded by the UK Engineering and Physical Sciences Research Council (EPSRC), the CytoCom Network formally met on five occasions to examine and discuss common issues in biology and computing that could be exploited to develop emerging models of computation.},
  file = {/home/oblivion/Zotero/storage/QNW6356R/9783642055690.html},
  langid = {english}
}

@online{ComputeIntersectionTwo,
  title = {Compute the Intersection of Two Regular Expressions in {{Python}} 3 @ {{Things Of Interest}}},
  url = {https://qntm.org/greenery},
  urldate = {2019-07-23},
  file = {/home/oblivion/Zotero/storage/KA3T58V9/greenery.html}
}

@online{containerumHowEasilyDeploy2018,
  title = {How to Easily Deploy a {{Drupal}} Instance on {{Kubernetes}}},
  author = {Containerum},
  date = {2018-12-25T10:15:23},
  url = {https://medium.com/containerum/how-to-easily-deploy-a-drupal-8-instance-on-kubernetes-b90acc7786b7},
  urldate = {2019-08-28},
  abstract = {We have updated the tutorial to make it easier to deploy Drupal. We will be deploying Drupal 8 with MySQL on Kubernetes.},
  file = {/home/oblivion/Zotero/storage/DYQ6RIXA/how-to-easily-deploy-a-drupal-8-instance-on-kubernetes-b90acc7786b7.html},
  langid = {english},
  organization = {{Medium}}
}

@inproceedings{csontosAccessibilityUsabilitySecurity2021,
  title = {Accessibility, Usability, and Security Evaluation of {{Hungarian}} Government Websites},
  booktitle = {Universal {{Access}} in the {{Information Society}}},
  author = {Csontos, Balázs and Heckl, István},
  year = 2021,
  doi = {10.1007/s10209-020-00716-9},
  langid = {english}
}

@article{csontosAccessibilityUsabilitySecurity2021a,
  title = {Accessibility, Usability, and Security Evaluation of {{Hungarian}} Government Websites},
  author = {Csontos, Balázs and Heckl, István},
  year = 2021,
  journaltitle = {Universal Access in the Information Society},
  shortjournal = {Univ Access Inf Soc},
  volume = {20},
  pages = {139--156},
  issn = {1615-5297},
  doi = {10.1007/s10209-020-00716-9},
  abstract = {Public sector bodies are increasingly relying on the Internet. On this channel, indispensable information is transmitted to the public and a wide range of services is already available. Therefore, the usability, accessibility, and the security of these websites are very important. Accessibility is particularly crucial for persons with disabilities. The accessibility of public service websites is regulated by a number of laws; among others, the directive “on the accessibility of the websites and mobile applications of public sector bodies” adopted by the European Parliament in 2016. This obliges all European Union member states to make all public sector websites and mobile applications accessible by 23 September 2021. In practice, this means that websites must fulfil the level AA recommendations in WCAG 2.1. In our study, a website assessment method is developed by comparing different analytical tools. With this method, we analysed how Hungarian websites of public sector bodies fulfil the requirements of the directive. We have also investigated how well they comply with usability and security guidelines. The results showed that none of the 25 websites of the examined Hungarian public sector bodies could completely fulfil the recommendations of the Web Content Accessibility Guidelines (WCAG) and that half of the websites had only the lowest level of compliance in usability tests. From the security point of view, almost half of the websites use outdated server versions and programming language, which is very critical. We have proposed several suggestions to address the major problems, so website developers and administrators can improve the accessibility, usability, and security aspects of these websites.},
  file = {/home/oblivion/Zotero/storage/MQSR7WVI/Csontos and Heckl - 2021 - Accessibility, usability, and security evaluation .pdf},
  langid = {english},
  number = {1}
}

@article{cuiContinuousOnlineSequence2016,
  title = {Continuous {{Online Sequence Learning}} with an {{Unsupervised Neural Network Model}}},
  author = {Cui, Yuwei and Ahmad, Subutai and Hawkins, Jeff},
  year = 2016,
  journaltitle = {Neural Computation},
  shortjournal = {Neural Computation},
  volume = {28},
  pages = {2474--2504},
  issn = {0899-7667},
  doi = {10.1162/NECO_a_00893},
  abstract = {The ability to recognize and predict temporal sequences of sensory inputs is vital for survival in natural environments. Based on many known properties of cortical neurons, hierarchical temporal memory (HTM) sequence memory recently has been proposed as a theoretical framework for sequence learning in the cortex. In this letter, we analyze properties of HTM sequence memory and apply it to sequence learning and prediction problems with streaming data. We show the model is able to continuously learn a large number of variable order temporal sequences using an unsupervised Hebbian-like learning rule. The sparse temporal codes formed by the model can robustly handle branching temporal sequences by maintaining multiple predictions until there is sufficient disambiguating evidence. We compare the HTM sequence memory with other sequence learning algorithms, including statistical methods—autoregressive integrated moving average; feedforward neural networks—time delay neural network and online sequential extreme learning machine; and recurrent neural networks—long short-term memory and echo-state networks on sequence prediction problems with both artificial and real-world data. The HTM model achieves comparable accuracy to other state-of-the-art algorithms. The model also exhibits properties that are critical for sequence learning, including continuous online learning, the ability to handle multiple predictions and branching sequences with high-order statistics, robustness to sensor noise and fault tolerance, and good performance without task-specific hyperparameter tuning. Therefore, the HTM sequence memory not only advances our understanding of how the brain may solve the sequence learning problem but is also applicable to real-world sequence learning problems from continuous data streams.},
  file = {/home/oblivion/Zotero/storage/33IMVRHV/Cui et al. - 2016 - Continuous Online Sequence Learning with an Unsupe.pdf;/home/oblivion/Zotero/storage/9SKXI66C/NECO_a_00893.html},
  number = {11}
}

@article{cuiHTMSpatialPooler2017,
  title = {The {{HTM Spatial Pooler}}—{{A Neocortical Algorithm}} for {{Online Sparse Distributed Coding}}},
  author = {Cui, Yuwei and Ahmad, Subutai and Hawkins, Jeff},
  year = 2017,
  journaltitle = {Frontiers in Computational Neuroscience},
  shortjournal = {Front. Comput. Neurosci.},
  volume = {11},
  issn = {1662-5188},
  doi = {10.3389/fncom.2017.00111},
  abstract = {Hierarchical temporal memory (HTM) provides a theoretical framework that models several key computational principles of the neocortex. In this paper we analyze an important component of HTM, the HTM spatial pooler (SP). The SP models how neurons learn feedforward connections and form efficient representations of the input. It converts arbitrary binary input patterns into sparse distributed representations (SDRs) using a combination of competitive Hebbian learning rules and homeostatic excitability control. We describe a number of key properties of the spatial pooler, including fast adaptation to changing input statistics, improved noise robustness through learning, efficient use of cells and robustness to cell death. In order to quantify these properties we develop a set of metrics that can be directly computed from the spatial pooler outputs. We show how the properties are met using these metrics and targeted artificial simulations. We then demonstrate the value of the spatial pooler in a complete end-to-end real-world HTM system. We discuss the relationship with neuroscience and previous studies of sparse coding. The HTM spatial pooler represents a neurally inspired algorithm for learning sparse representations from noisy data streams in an online fashion.},
  file = {/home/oblivion/Zotero/storage/US2MV45N/Cui et al. - 2017 - The HTM Spatial Pooler—A Neocortical Algorithm for.pdf},
  keywords = {competitive learning,Hebbian Learning,Hierarchical temporal memory (HTM),Online Learning,sparse distributed representations,sparse representation,spatial pooling},
  langid = {english}
}

@thesis{dalmazoPredictionbasedApproachAnomaly2018,
  title = {A {{Prediction}}-Based {{Approach}} for {{Anomaly Detection}} in the {{Cloud}}},
  author = {Dalmazo, Bruno Lopes},
  year = 2018,
  institution = {{00500::Universidade de Coimbra}},
  url = {https://estudogeral.sib.uc.pt/handle/10316/81235},
  urldate = {2021-04-18},
  abstract = {Computer networks are present everywhere, making them a key aspect to the proper functioning of products and services that are often served exclusively through the Internet. The pervasive nature of computer networks makes them particularly suitable to attacks. Therefore, more than just functional systems, we are also looking for systems that are reliable, available, scalable and secure.   A solution to meet the growing demands of industries and customers alike is cloud computing. Among several other advantages of this paradigm, the possibility of increased profits by reducing costs with infrastructure and software licenses, while allowing for virtually unlimited growth is particularly relevant. However, these advantages are many times shadowed by the increased security risks that steam from having different entities involved, with relationships and responsibilities not properly identified. This may lead to misuse or malicious attacks against cloud computing, which may compromise sensitive information that is stored in shared third party facilities, and many open issues still prevail.   Due to these and other issues, it is extremely important to devise new solutions that increase the trustworthiness of cloud computing environments and help to keep the continued growth in demand for virtualized resources. Facing this challenge, this work aims to study, analyze, propose, develop and evaluate several models and mechanisms to fill these gaps. Firstly, a systematic approach for selecting a group of candidate predictors that is suitable for cloud network traffic prediction is proposed. On the basis of this scenario, a predictor model for cloud network traffic that involves a tradeoff between prediction error, historical data dependence, computational costs, and timely response is proposed. Next, an Anomaly Detection System to support decision-making and counter attack malicious actions against cloud computing systems is presented. This contribution relies on network traffic prediction to obtain features that represent the expected appropriate behaviour of the cloud network traffic used jointly with a Support Vector Machine model for detecting anomalous events in the cloud environment. Finally, a mechanism for determining the similarity level between features of the alarms is proposed. This mechanism aims to optimize the efficiency for generating alarms, decreasing the network data traffic to manage the IDS and its associated transfer costs. The benefits and drawbacks of the contributions were demonstrated in realistic simulations using data from real network traces. Furthermore, the evaluations were conducted with well-known metrics and the results show that all the proposed mechanisms were able to outperform similar proposals in literature.},
  annotation = {Accepted: 2018-11-02T16:33:44Z},
  file = {/home/oblivion/Zotero/storage/463I42WG/81235.html},
  langid = {english},
  type = {doctoralThesis}
}

@book{damasioDescartesError2006,
  title = {Descartes' {{Error}}},
  author = {Damasio, Antonio R.},
  year = 2006,
  publisher = {{Vintage}},
  abstract = {\&quot;Although I cannot tell for certain what sparked my interest in the neural underpinnings of reason, I do know when I became convinced that the traditional views on the nature of rationality could not be correct.\&quot; Thus begins a book that takes the reader on a journey of discovery, from the story of Phineas Gage, the famous nineteenth-century case of behavioral change that followed brain damage, to the contemporary recreation of Gage\&\#39;s brain; and from the doubts of a young neurologist to a testable hypothesis concerning the emotions and their fundamental role in rational human behavior. Drawing on his experiences with neurological patients affected by brain damage (his laboratory is recognized worldwide as the foremost center for the study of such patients), Antonio Damasio shows how the absence of emotion and feeling can break down rationality. In the course of explaining how emotions and feelings contribute to reason and to adaptive social behavior, Damasio also offers a novel perspective on what emotions and feelings actually are: a direct sensing of our own body states, a link between the body and its survival-oriented regulations, on the one hand, and consciousness, on the other. Descartes\&\#39; Error leads us to conclude that human organisms are endowed from the very beginning with a spirited passion for making choices, which the social mind can use to build rational behavior.},
  eprint = {5aczCwAAQBAJ},
  eprinttype = {googlebooks},
  isbn = {978-0-09-950164-0},
  langid = {english},
  pagetotal = {354}
}

@article{damasioNatureFeelingsEvolutionary2013,
  title = {The Nature of Feelings: Evolutionary and Neurobiological Origins},
  shorttitle = {The Nature of Feelings},
  author = {Damasio, Antonio and Carvalho, Gil B.},
  year = 2013,
  journaltitle = {Nature Reviews Neuroscience},
  volume = {14},
  pages = {143--152},
  issn = {1471-0048},
  doi = {10.1038/nrn3403},
  abstract = {Feelings are mental experiences of body states. They signify physiological need (for example, hunger), tissue injury (for example, pain), optimal function (for example, well-being), threats to the organism (for example, fear or anger) or specific social interactions (for example, compassion, gratitude or love). Feelings constitute a crucial component of the mechanisms of life regulation, from simple to complex. Their neural substrates can be found at all levels of the nervous system, from individual neurons to subcortical nuclei and cortical regions.},
  file = {/home/oblivion/Zotero/storage/22VACDLB/nrn3403.html},
  langid = {english},
  number = {2}
}

@online{DeepLearningIoT,
  title = {Deep {{Learning}} for {{IoT Big Data}} and {{Streaming Analytics}}: {{A Survey}} - {{IEEE Journals}} \& {{Magazine}}},
  url = {https://ieeexplore.ieee.org/abstract/document/8373692},
  urldate = {2019-05-30},
  file = {/home/oblivion/Zotero/storage/R4SCYBK2/8373692.html}
}

@article{defelipeNeocorticalColumn2012,
  title = {The {{Neocortical Column}}},
  author = {Defelipe, Javier and Markram, Henry and Rockland, Kathleen S.},
  year = 2012,
  journaltitle = {Frontiers in Neuroanatomy},
  shortjournal = {Front. Neuroanat.},
  volume = {6},
  issn = {1662-5129},
  doi = {10.3389/fnana.2012.00022},
  abstract = {The Neocortical Column},
  file = {/home/oblivion/Zotero/storage/BMX5YP58/Defelipe et al. - 2012 - The Neocortical Column.pdf},
  keywords = {Cerebral Cortex,cortical processes,cortical unit,macrocolumn’s function,minicolumns,neocortical column},
  langid = {english}
}

@article{departmentofinformationsystemsfacultyofcomputersinformationhelwanuniversityainhelwanhelwancairoegyptDetectionPerformanceAnomalies2016,
  title = {Detection of {{Performance Anomalies}} in {{Cloud Services}}: {{A Correlation Analysis Approach}}},
  shorttitle = {Detection of {{Performance Anomalies}} in {{Cloud Services}}},
  author = {{Department of Information Systems Faculty of Computers \& Information, Helwan University Ain Helwan, Helwan, Cairo, Egypt} and Abdelrahman, Ghodai M.},
  year = 2016,
  journaltitle = {International Journal of Mechanical Engineering and Information Technology},
  shortjournal = {ijmeit},
  issn = {2348196X},
  doi = {10.18535/ijmeit/v4i9.06},
  abstract = {The prevalence of ubiquitous computing and communication has coined the term of cloud computing through which, software, infrastructure and platform can be provided as a service. Software as a service (SaaS) is getting an increasing potential as a cloud-based option for using software applications in a payper-use manner. A critical challenge in SaaS model is continuous attestation of the compliance with quality of service (QoS) metrics stated in SLAs. In this paper, we propose a method for detecting performance anomalies in cloud software services. The proposed method uses correlation analysis between computing resources utilization and workload characteristics. This is done by comparing the correlation values to a reference load test values performed before the SaaS deployment to identify deviations and notify the system administrator about it. The testing scenario operates in two steps. First, running a standard benchmark on a virtual machine to simulate workload and record the correlation between workload and available computing resources utilization (i.e., CPU, RAM, HDD, and Network). Second, the same benchmark is executed again but with changing the workload characteristics through injecting additional queries or changing the computing resources configuration values of the virtual machine. The changes are only present on specific time points to testify the detection rate. Results on standard benchmarks TPC-C, TPC-D and TPC-W showed a promising detection rate that can assure SLA targeted quality aspects such as reliability, scalability and security.},
  file = {/home/oblivion/Zotero/storage/RNU65KGC/Department of Information Systems Faculty of Computers & Information, Helwan University Ain Helwan, Helwan, Cairo, Egypt and Abdelrahman - 2016 - Detection of Performance Anomalies in Cloud Servic.pdf},
  langid = {english}
}

@article{doyaWhatAreComputations1999,
  title = {What Are the Computations of the Cerebellum, the Basal Ganglia and the Cerebral Cortex?},
  author = {Doya, K.},
  year = 1999,
  journaltitle = {Neural Networks: The Official Journal of the International Neural Network Society},
  shortjournal = {Neural Netw},
  volume = {12},
  pages = {961--974},
  issn = {1879-2782},
  abstract = {The classical notion that the cerebellum and the basal ganglia are dedicated to motor control is under dispute given increasing evidence of their involvement in non-motor functions. Is it then impossible to characterize the functions of the cerebellum, the basal ganglia and the cerebral cortex in a simplistic manner? This paper presents a novel view that their computational roles can be characterized not by asking what are the "goals" of their computation, such as motor or sensory, but by asking what are the "methods" of their computation, specifically, their learning algorithms. There is currently enough anatomical, physiological, and theoretical evidence to support the hypotheses that the cerebellum is a specialized organism for supervised learning, the basal ganglia are for reinforcement learning, and the cerebral cortex is for unsupervised learning.This paper investigates how the learning modules specialized for these three kinds of learning can be assembled into goal-oriented behaving systems. In general, supervised learning modules in the cerebellum can be utilized as "internal models" of the environment. Reinforcement learning modules in the basal ganglia enable action selection by an "evaluation" of environmental states. Unsupervised learning modules in the cerebral cortex can provide statistically efficient representation of the states of the environment and the behaving system. Two basic action selection architectures are shown, namely, reactive action selection and predictive action selection. They can be implemented within the anatomical constraint of the network linking these structures. Furthermore, the use of the cerebellar supervised learning modules for state estimation, behavioral simulation, and encapsulation of learned skill is considered. Finally, the usefulness of such theoretical frameworks in interpreting brain imaging data is demonstrated in the paradigm of procedural learning.},
  eprint = {12662639},
  eprinttype = {pmid},
  langid = {english},
  number = {7-8}
}

@incollection{dreyfusMakingMindModelling1991,
  title = {Making a {{Mind Versus Modelling}} the {{Brain}}: {{Artificial Intelligence Back}} at the {{Branchpoint}}},
  shorttitle = {Making a {{Mind Versus Modelling}} the {{Brain}}},
  booktitle = {Understanding the {{Artificial}}: {{On}} the {{Future Shape}} of {{Artificial Intelligence}}},
  author = {Dreyfus, Hubert L. and Dreyfus, Stuart E.},
  editor = {Negrotti, Massimo},
  year = 1991,
  pages = {33--54},
  publisher = {{Springer London}},
  location = {{London}},
  doi = {10.1007/978-1-4471-1776-6_3},
  abstract = {In the early 1950s, as calculating machines were coming into their own, a few pioneer thinkers began to realise that digital computers could be more than number-crunchers. At that point two opposed visions of what computers could be, each with its correlated research programme, emerged and struggled for recognition. One faction saw computers as a system for manipulating mental symbols; the other, as a medium for modelling the brain. One sought to use computers to instantiate a formal representation of the world; the other, to simulate the interactions of neurons. One took problem solving as its paradigm of intelligence; the other, learning. One utilised logic; the other, statistics. One school was the heir to the rationalist, reductionist tradition in philosophy; the other viewed itself as idealised, holistic neuroscience.},
  isbn = {978-1-4471-1776-6},
  keywords = {Cognitive Science Society,Everyday World,Hide Node,Intelligent Behaviour,Symbolic Representation},
  langid = {english},
  series = {Artificial {{Intelligence}} and {{Society}}}
}

@misc{drupalcommunityExploreFeaturedCase,
  title = {Explore Featured Case Studies},
  howpublished = "\url{https://www.drupal.org/case-studies}",
  year = {2021},
  note = "Accessed: 2021-02-21",
}

@online{DrupalMultisiteMuch,
  title = {Drupal {{Multisite}}: {{Much Ado About Drupal Multisite}} | {{Pantheon}}},
  url = {https://pantheon.io/blog/drupal-multisite-much-ado-about-drupal-multisite},
  urldate = {2021-02-27},
  file = {/home/oblivion/Zotero/storage/Q5JQ4VRG/drupal-multisite-much-ado-about-drupal-multisite.html}
}

@online{DrupalOperatorKubernetes,
  title = {A {{Drupal Operator}} for {{Kubernetes}} with the {{Ansible Operator SDK}} | {{Jeff Geerling}}},
  url = {https://www.jeffgeerling.com/blog/2019/drupal-operator-kubernetes-ansible-operator-sdk},
  urldate = {2019-08-28},
  file = {/home/oblivion/Zotero/storage/EJGX8QLS/drupal-operator-kubernetes-ansible-operator-sdk.html}
}

@article{einevollScientificCaseBrain2019,
  title = {The {{Scientific Case}} for {{Brain Simulations}}},
  author = {Einevoll, Gaute T. and Destexhe, Alain and Diesmann, Markus and Grün, Sonja and Jirsa, Viktor and family=Kamps, given=Marc, prefix=de, useprefix=true and Migliore, Michele and Ness, Torbjørn V. and Plesser, Hans E. and Schürmann, Felix},
  year = 2019,
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {102},
  pages = {735--744},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2019.03.027},
  abstract = {A key element of the European Union’s Human Brain Project (HBP) and other large-scale brain research projects is the simulation of large-scale model networks of neurons. Here, we argue why such simulations will likely be indispensable for bridging the scales between the neuron and system levels in the brain, and why a set of brain simulators based on neuron models at different levels of biological detail should therefore be developed. To allow for systematic refinement of candidate network models by comparison with experiments, the simulations should be multimodal in the sense that they should predict not only action potentials, but also electric, magnetic, and optical signals measured at the population and system levels.},
  file = {/home/oblivion/Zotero/storage/TFJFJI2J/Einevoll et al. - 2019 - The Scientific Case for Brain Simulations.pdf;/home/oblivion/Zotero/storage/LSUAWGWL/S0896627319302909.html},
  keywords = {brain simulation,model,network,neuron,simulation,simulator},
  number = {4}
}

@online{etheredgeSoftwareComplexityKilling2018,
  title = {Software {{Complexity Is Killing Us}}},
  author = {Etheredge, Justin},
  date = {2018-01-29T20:07:06+00:00},
  url = {https://www.simplethread.com/software-complexity-killing-us/},
  urldate = {2021-02-25},
  abstract = {Since the dawn of time (before software, there was only darkness), there has been one constant: businesses want to build software cheaper and faster. It is certainly an understandable and laudable goal – especially if you’ve spent any time around software developers. It is a goal that every engineer should support wholeheartedly, and we should […]},
  file = {/home/oblivion/Zotero/storage/6A8RQYI8/software-complexity-killing-us.html},
  langid = {american},
  organization = {{Simple Thread}}
}

@inproceedings{fairbanksUrTechnicalDebt2020a,
  title = {Ur-Technical Debt},
  author = {Fairbanks, George},
  year = 2020,
  journaltitle = {IEEE Software},
  issn = {1937-4194},
  doi = {10.1109/MS.2020.2986613},
  abstract = {These days, everyone uses the term technical debt. It's so prevalent that we shorten it to tech debt tech debt or even just TD. Tech debt is also hacky code, code written by novices, code written without consideration of software architecture (so-called big balls of mud), and code with antipatterns flagged by static analysis tools.},
}

@article{fanBriefHistorySimulation2019,
  title = {A {{Brief History}} of {{Simulation Neuroscience}}},
  author = {Fan, Xue and Markram, Henry},
  year = 2019,
  journaltitle = {Frontiers in Neuroinformatics},
  shortjournal = {Front. Neuroinform.},
  volume = {13},
  issn = {1662-5196},
  doi = {10.3389/fninf.2019.00032},
  abstract = {Our knowledge of the brain has evolved over millennia in philosophical, experimental and theoretical phases. We suggest that the next phase is simulation neuroscience. The main drivers of simulation neuroscience are big data generated at multiple levels of brain organization and the need to integrate these data to trace the causal chain of interactions within and across all these levels. Simulation neuroscience is currently the only methodology for systematically approaching the multiscale brain. In this review, we attempt to reconstruct the deep historical paths leading to simulation neuroscience, from the first observations of the nerve cell to modern efforts to digitally reconstruct and simulate the brain. Neuroscience began with the identification of the neuron as the fundamental unit of brain structure and function and has evolved towards understanding the role of each cell type in the brain, how brain cells are connected to each other, and how the seemingly infinite networks they form give rise to the vast diversity of brain functions. Neuronal mapping is evolving from subjective descriptions of cell types towards objective classes, subclasses and types. Connectivity mapping is evolving from loose topographic maps between brain regions towards dense anatomical and physiological maps of connections between individual genetically distinct neurons. Functional mapping is evolving from psychological and behavioral stereotypes towards a map of behaviors emerging from structural and functional connectomes. We show how industrialization of neuroscience and the resulting large disconnected datasets are generating demand for integrative neuroscience, how the scale of neuronal and connectivity maps is driving digital atlasing and digital reconstruction to piece together the multiple levels of brain organization, and how the complexity of the interactions between molecules, neurons, microcircuits and brain regions is driving brain simulation to understand the interactions in the multiscale brain.},
  file = {/home/oblivion/Zotero/storage/CVFAM3YI/Fan and Markram - 2019 - A Brief History of Simulation Neuroscience.pdf},
  keywords = {Brain structure and function,connectome,Digital reconstruction,History,neuronal types,simulation neuroscience},
  langid = {english}
}

@article{foldiakFormingSparseRepresentations1990,
  title = {Forming Sparse Representations by Local Anti-{{Hebbian}} Learning},
  author = {Földiák, P.},
  year = 1990,
  journaltitle = {Biological Cybernetics},
  shortjournal = {Biol. Cybern.},
  volume = {64},
  pages = {165--170},
  issn = {1432-0770},
  doi = {10.1007/BF02331346},
  abstract = {How does the brain form a useful representation of its environment? It is shown here that a layer of simple Hebbian units connected by modifiable anti-Hebbian feed-back connections can learn to code a set of patterns in such a way that statistical dependency between the elements of the representation is reduced, while information is preserved. The resulting code is sparse, which is favourable if it is to be used as input to a subsequent supervised associative layer. The operation of the network is demonstrated on two simple problems.},
  keywords = {Associative Layer,Simple Problem,Sparse Representation,Statistical Dependency},
  langid = {english},
  number = {2}
}

@article{foldiakFormingSparseRepresentations1990a,
  title = {Forming Sparse Representations by Local Anti-{{Hebbian}} Learning},
  author = {Földiák, P.},
  year = 1990,
  journaltitle = {Biological Cybernetics},
  shortjournal = {Biol. Cybern.},
  volume = {64},
  pages = {165--170},
  issn = {1432-0770},
  doi = {10.1007/BF02331346},
  abstract = {How does the brain form a useful representation of its environment? It is shown here that a layer of simple Hebbian units connected by modifiable anti-Hebbian feed-back connections can learn to code a set of patterns in such a way that statistical dependency between the elements of the representation is reduced, while information is preserved. The resulting code is sparse, which is favourable if it is to be used as input to a subsequent supervised associative layer. The operation of the network is demonstrated on two simple problems.},
  keywords = {Associative Layer,Simple Problem,Sparse Representation,Statistical Dependency},
  langid = {english},
  number = {2}
}

@article{freundInterneurons2008,
  title = {Interneurons},
  author = {Freund, Tamas and Kali, Szabolcs},
  year = 2008,
  journaltitle = {Scholarpedia},
  volume = {3},
  pages = {4720},
  issn = {1941-6016},
  doi = {10.4249/scholarpedia.4720},
  file = {/home/oblivion/Zotero/storage/X5JFW6PU/Interneurons.html},
  langid = {english},
  number = {9}
}

@online{FundamentalsBrainDevelopment,
  title = {The {{Fundamentals}} of {{Brain Development}}: {{Integrating Nature}} and {{Nurture}} - {{Joan Stiles}}, {{Emeritus Professor}} of {{Cognitive Sciences Joan Stiles}} - {{Google Books}}},
  url = {https://books.google.gr/books/about/The_Fundamentals_of_Brain_Development.html?id=BAbSGxIINYoC&printsec=frontcover&source=kp_read_button&redir_esc=y#v=onepage&q&f=false},
  urldate = {2019-05-29},
  file = {/home/oblivion/Zotero/storage/XRJ9XQVJ/The_Fundamentals_of_Brain_Development.html}
}

@article{gaoMicroRNAMiRNAProfiling2016,
  title = {{{MicroRNA}} ({{miRNA}}) {{Profiling}}},
  author = {Gao, Lu and Jiang, Feng},
  year = 2016,
  journaltitle = {Methods in Molecular Biology (Clifton, N.J.)},
  shortjournal = {Methods Mol. Biol.},
  volume = {1381},
  pages = {151--161},
  issn = {1940-6029},
  doi = {10.1007/978-1-4939-3204-7_8},
  abstract = {MicroRNAs (miRNAs) are small, highly conserved noncoding RNA molecules involved in the regulation of gene expression. Since each miRNA regulates the expression of hundreds of target mRNAs, miRNAs could function as master coordinators, efficiently regulating fundamental cellular processes, including proliferation, apoptosis, and development. Furthermore, miRNAs may provide useful diagnostic and therapeutic targets in a variety of diseases. However, miRNA expression profiling is essential for the investigation of the biological functions and clinical applications of miRNAs. Therefore, in this chapter, we review and discuss commonly used techniques for miRNAs profiling, as well as their advantages and restrictions.},
  eprint = {26667459},
  eprinttype = {pmid},
  file = {/home/oblivion/Zotero/storage/29MF2MVF/Gao and Jiang - 2016 - MicroRNA (miRNA) Profiling.pdf},
  keywords = {Animals,DDPCR,Gene Expression Profiling,Gene Library,High-Throughput Nucleotide Sequencing,Humans,Microarray,MicroRNAs,miRNA,Oligonucleotide Array Sequence Analysis,Polymerase Chain Reaction},
  langid = {english}
}

@book{goertzelAdvancesArtificialGeneral2007,
  title = {Advances in {{Artificial General Intelligence}}: {{Concepts}}, {{Architectures}} and {{Algorithms}} : {{Proceedings}} of the {{AGI Workshop}} 2006},
  shorttitle = {Advances in {{Artificial General Intelligence}}},
  author = {Goertzel, Ben and Wang, Pei},
  year = 2007,
  publisher = {{IOS Press}},
  abstract = {"The topic of this book the creation of software programs displaying broad, deep, human-style general intelligence is a grand and ambitious one. And yet it is far from a frivolous one: what the papers in this publication illustrate is that it is a fit and proper subject for serious science and engineering exploration. No one has yet created a software program with human-style or (even roughly) human-level general intelligence but we now have a sufficiently rich intellectual toolkit that it is possible to think about such a possibility in detail, and make serious attempts at design, analysis and engineering. possibility in detail, and make serious attempts at design, analysis and engineering. This is the situation that led to the organization of the 2006 AGIRI (Artificial General Intelligence Research Institute) workshop; and to the decision to publish a book from contributions by the speakers at the conference.The material presented here only scratches the surface of the AGI-related R\&D work that is occurring around the world at this moment. But the editors are pleased to have had the chance to be involved in organizing and presenting at least a small percentage of the contemporary progress."},
  eprint = {t2G5srpFRhEC},
  eprinttype = {googlebooks},
  isbn = {978-1-58603-758-1},
  keywords = {Computers / Intelligence (AI) & Semantics},
  langid = {english},
  pagetotal = {305}
}

@inproceedings{haririBatchOnlineAnomaly2018,
  title = {Batch and Online Anomaly Detection for Scientific Applications in a {{Kubernetes}} Environment},
  booktitle = {{{ScienceCloud}}@{{HPDC}}},
  author = {Hariri, S. and Kind, M. C.},
  year = 2018,
  doi = {10.1145/3217880.3217883},
  abstract = {We present a cloud based anomaly detection service framework that uses a containerized Spark cluster and ancillary user interfaces all managed by Kubernetes. The stack of technology put together allows for fast, reliable, resilient and easily scalable service for either batch or streaming data. At the heart of the service, we utilize an improved version of the algorithm Isolation Forest called Extended Isolation Forest for robust and efficient anomaly detection. We showcase the design and a normal workflow of our infrastructure which is ready to deploy on any Kubernetes cluster without extra technical knowledge. With exposed APIs and simple graphical interfaces, users can load any data and detect anomalies on the loaded set or on newly presented data points using a batch or a streaming mode. With the latter, users can subscribe and get notifications on the desired output. Our aim is to develop and apply these techniques to use with scientific data. In particular we are interested in finding anomalous objects within the overwhelming set of images and catalogs produced by current and future astronomical surveys, but that can be easily adopted to other fields.}
}

@inproceedings{haririBatchOnlineAnomaly2018a,
  title = {Batch and Online Anomaly Detection for Scientific Applications in a {{Kubernetes}} Environment},
  booktitle = {Proceedings of the 9th {{Workshop}} on {{Scientific Cloud Computing}}},
  author = {Hariri, Sahand and Kind, Matias Carrasco},
  year = 2018,
  pages = {1--7},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/3217880.3217883},
  abstract = {We present a cloud based anomaly detection service framework that uses a containerized Spark cluster and ancillary user interfaces all managed by Kubernetes. The stack of technology put together allows for fast, reliable, resilient and easily scalable service for either batch or streaming data. At the heart of the service, we utilize an improved version of the algorithm Isolation Forest called Extended Isolation Forest for robust and efficient anomaly detection. We showcase the design and a normal workflow of our infrastructure which is ready to deploy on any Kubernetes cluster without extra technical knowledge. With exposed APIs and simple graphical interfaces, users can load any data and detect anomalies on the loaded set or on newly presented data points using a batch or a streaming mode. With the latter, users can subscribe and get notifications on the desired output. Our aim is to develop and apply these techniques to use with scientific data. In particular we are interested in finding anomalous objects within the overwhelming set of images and catalogs produced by current and future astronomical surveys, but that can be easily adopted to other fields.},
  isbn = {978-1-4503-5863-7},
  keywords = {Anomaly Detection,Apache Spark,Cloud Computing,Isolation Forest,Kubernetes},
  series = {{{ScienceCloud}}'18}
}

@article{haueisLifeCorticalColumn2016,
  title = {The Life of the Cortical Column: Opening the Domain of Functional Architecture of the Cortex (1955–1981)},
  shorttitle = {The Life of the Cortical Column},
  author = {Haueis, Philipp},
  year = 2016,
  journaltitle = {History and Philosophy of the Life Sciences},
  shortjournal = {Hist Philos Life Sci},
  volume = {38},
  issn = {0391-9714},
  doi = {10.1007/s40656-016-0103-4},
  abstract = {The concept of the cortical column refers to vertical cell bands with similar response properties, which were initially observed by Vernon Mountcastle’s mapping of single cell recordings in the cat somatic cortex. It has subsequently guided over 50~years of neuroscientific research, in which fundamental questions about the modularity of the cortex and basic principles of sensory information processing were empirically investigated. Nevertheless, the status of the column remains controversial today, as skeptical commentators proclaim that the vertical cell bands are a functionally insignificant by-product of ontogenetic development. This paper inquires how the column came to be viewed as an elementary unit of the cortex from Mountcastle’s discovery in 1955 until David Hubel and Torsten Wiesel’s reception of the Nobel Prize in 1981. I first argue that Mountcastle’s vertical electrode recordings served as criteria for applying the column concept to electrophysiological data. In contrast to previous authors, I claim that this move from electrophysiological data to the phenomenon of columnar responses was concept-laden, but not theory-laden. In the second part of the paper, I argue that Mountcastle’s criteria provided Hubel Wiesel with a conceptual outlook, i.e. it allowed them to anticipate columnar patterns in the cat and macaque visual cortex. I argue that in the late 1970s, this outlook only briefly took a form that one could call a ‘theory’ of the cerebral cortex, before new experimental techniques started to diversify column research. I end by showing how this account of early column research fits into a larger project that follows the conceptual development of the column into the present.},
  eprint = {27325058},
  eprinttype = {pmid},
  file = {/home/oblivion/Zotero/storage/YWVCY48L/Haueis - 2016 - The life of the cortical column opening the domai.pdf},
  number = {3},
  pmcid = {PMC4914527}
}

@article{hawkinsFrameworkIntelligenceCortical2019,
  title = {A {{Framework}} for {{Intelligence}} and {{Cortical Function Based}} on {{Grid Cells}} in the {{Neocortex}}},
  author = {Hawkins, Jeff and Lewis, Marcus and Klukas, Mirko and Purdy, Scott and Ahmad, Subutai},
  year = 2019,
  journaltitle = {Frontiers in Neural Circuits},
  shortjournal = {Front. Neural Circuits},
  volume = {12},
  issn = {1662-5110},
  doi = {10.3389/fncir.2018.00121},
  abstract = {How the neocortex works is a mystery. In this paper we propose a novel framework for understanding its function. Grid cells are neurons in the entorhinal cortex that represent the location of an animal in its environment. Recent evidence suggests that grid cell-like neurons may also be present in the neocortex. We propose that grid cells exist throughout the neocortex, in every region and in every cortical column. They define a location-based framework for how the neocortex functions. Whereas grid cells in the entorhinal cortex represent the location of one thing, the body relative to its environment, we propose that cortical grid cells simultaneously represent the location of many things. Cortical columns in somatosensory cortex track the location of tactile features relative to the object being touched and cortical columns in visual cortex track the location of visual features relative to the object being viewed. We propose that mechanisms in the entorhinal cortex and hippocampus that evolved for learning the structure of environments are now used by the neocortex to learn the structure of objects. Having a representation of location in each cortical column suggests mechanisms for how the neocortex represents object compositionality and object behaviors. It leads to the hypothesis that every part of the neocortex learns complete models of objects and that there are many models of each object distributed throughout the neocortex. The similarity of circuitry observed in all cortical regions is strong evidence that even high-level cognitive tasks are learned and represented in a location-based framework.},
  file = {/home/oblivion/Zotero/storage/AEIFGNAP/Hawkins et al. - 2019 - A Framework for Intelligence and Cortical Function.pdf},
  keywords = {cortical column,Grid Cell,hierarchy,Neocortex,neocortical theory,object recognition},
  langid = {english}
}

@article{hawkinsTheoryHowColumns2017,
  title = {A {{Theory}} of {{How Columns}} in the {{Neocortex Enable Learning}} the {{Structure}} of the {{World}}},
  author = {Hawkins, Jeff and Ahmad, Subutai and Cui, Yuwei},
  year = 2017,
  journaltitle = {Frontiers in Neural Circuits},
  shortjournal = {Front. Neural Circuits},
  volume = {11},
  issn = {1662-5110},
  doi = {10.3389/fncir.2017.00081},
  abstract = {Neocortical regions are organized into columns and layers. Connections between layers run mostly perpendicular to the surface suggesting a columnar functional organization. Some layers have long-range excitatory lateral connections suggesting interactions between columns. Similar patterns of connectivity exist in all regions but their exact role remain a mystery. In this paper, we propose a network model composed of columns and layers that performs robust object learning and recognition. Each column integrates its changing input over time to learn complete predictive models of observed objects. Excitatory lateral connections across columns allow the network to more rapidly infer objects based on the partial knowledge of adjacent columns. Because columns integrate input over time and space, the network learns models of complex objects that extend well beyond the receptive field of individual cells. Our network model introduces a new feature to cortical columns. We propose that a representation of location relative to the object being sensed is calculated within the sub-granular layers of each column. The location signal is provided as an input to the network, where it is combined with sensory data. Our model contains two layers and one or more columns. Simulations show that using Hebbian-like learning rules small single-column networks can learn to recognize hundreds of objects, with each object containing tens of features. Multi-column networks recognize objects with significantly fewer movements of the sensory receptors. Given the ubiquity of columnar and laminar connectivity patterns throughout the neocortex, we propose that columns and regions have more powerful recognition and modeling capabilities than previously assumed.},
  file = {/home/oblivion/Zotero/storage/GBRQ6AA2/Hawkins et al. - 2017 - A Theory of How Columns in the Neocortex Enable Le.pdf},
  keywords = {cortical columns,cortical layers,Hierarchical temporal memory,Neocortex,sensorimotor learning},
  langid = {english}
}

@article{hawkinsWhyNeuronsHave2016,
  title = {Why {{Neurons Have Thousands}} of {{Synapses}}, a {{Theory}} of {{Sequence Memory}} in {{Neocortex}}},
  author = {Hawkins, Jeff and Ahmad, Subutai},
  year = 2016,
  journaltitle = {Frontiers in Neural Circuits},
  shortjournal = {Front. Neural Circuits},
  volume = {10},
  issn = {1662-5110},
  doi = {10.3389/fncir.2016.00023},
  abstract = {Pyramidal neurons represent the majority of excitatory neurons in the neocortex. Each pyramidal neuron receives input from thousands of excitatory synapses that are segregated onto dendritic branches. The dendrites themselves are segregated into apical, basal, and proximal integration zones, which have different properties. It is a mystery how pyramidal neurons integrate the input from thousands of synapses, what role the different dendrites play in this integration, and what kind of network behavior this enables in cortical tissue. It has been previously proposed that non-linear properties of dendrites enable cortical neurons to recognize multiple independent patterns. In this paper we extend this idea in multiple ways. First we show that a neuron with several thousand synapses segregated on active dendrites can recognize hundreds of independent patterns of cellular activity even in the presence of large amounts of noise and pattern variation. We then propose a neuron model where patterns detected on proximal dendrites lead to action potentials, defining the classic receptive field of the neuron, and patterns detected on basal and apical dendrites act as predictions by slightly depolarizing the neuron without generating an action potential. By this mechanism, a neuron can predict its activation in hundreds of independent contexts. We then present a network model based on neurons with these properties that learns time-based sequences. The network relies on fast local inhibition to preferentially activate neurons that are slightly depolarized. Through simulation we show that the network scales well and operates robustly over a wide range of parameters as long as the network uses a sparse distributed code of cellular activations. We contrast the properties of the new network model with several other neural network models to illustrate the relative capabilities of each. We conclude that pyramidal neurons with thousands of synapses, active dendrites, and multiple integration zones create a robust and powerful sequence memory. Given the prevalence and similarity of excitatory neurons throughout the neocortex and the importance of sequence memory in inference and behavior, we propose that this form of sequence memory may be a universal property of neocortical tissue.},
  file = {/home/oblivion/Zotero/storage/L7HYXAUY/Hawkins and Ahmad - 2016 - Why Neurons Have Thousands of Synapses, a Theory o.pdf},
  keywords = {active dendrites,Cortex,Neurons,NMDA spike,sparse distributed representations},
  langid = {english}
}

@article{heisermanMotionPrintBiometricRealTime2020,
  title = {Motion-{{Print}}: {{A Biometric}} for {{Real}}-{{Time Pilot Identification}} Using {{Hierarchical Temporal Memory}}},
  shorttitle = {Motion-{{Print}}},
  author = {Heiserman, Sam and Zaychik, Kirill and Miller, Timothy},
  year = 2020,
  doi = {10.36227/techrxiv.12404393.v1},
  abstract = {This study presents a novel biometric approach to identify operators, given only streams of their control movements within a manual control task setting. In the present task subjects control a simulated, remotely operated robotic arm, attempting to dock onto a satellite in orbit. The proposed methodology utilizes the Hierarchical Temporal Memory (HTM) algorithm to distinguish operators by their unique control behaviors. Results presented compare the identification performance of HTM with Dynamic Time Warping (DTW) and Edit Distance on Real Sequences (EDR), in both static and real-time data settings. The HTM method outperformed both DTW and EDR in the real- time setting, and matched DTW in the static setting. Observed superior performance of the HTM algorithm lays the foundation for the extension of the proposed methodology to other motion- monitoring applications, such as real-time workload assessment, motion/simulator sickness onset or distraction detection.The data gathered in the study was posted to IEEE-dataport, DOI: 10.21227/wpyf-r927},
  file = {/home/oblivion/Zotero/storage/LZNNF995/12404393.pdf},
  langid = {english}
}

@inproceedings{hendersonSoftwareEngineeringGoogle2020,
  title = {Software {{Engineering}} at {{Google}}},
  author = {Henderson, Fergus},
  year = 2020,
  url = {http://arxiv.org/abs/1702.01715},
  urldate = {2021-02-25},
  abstract = {We catalog and describe Google's key software engineering practices.},
  archiveprefix = {arXiv},
  eprint = {1702.01715},
  eprinttype = {arxiv},
  file = {/home/oblivion/Zotero/storage/TT42WNNG/Henderson - 2020 - Software Engineering at Google.pdf;/home/oblivion/Zotero/storage/XYCCJDAI/1702.html},
  keywords = {Computer Science - Software Engineering,D.2},
  primaryclass = {cs}
}

@online{operatorPattern,
  title = "Operator Pattern",
  year = 2021,
  howpublished = {\url{https://kubernetes.io/docs/concepts/extend-kubernetes/operator}},
  note = "Accessed: 2021-06-03",
}

@online{hendersonSoftwareEngineeringGoogle2020a,
  title = {Software {{Engineering}} at {{Google}}},
  author = {Henderson, Fergus},
  year = 2020,
  url = {http://arxiv.org/abs/1702.01715},
  urldate = {2021-04-29},
  abstract = {We catalog and describe Google's key software engineering practices.},
  archiveprefix = {arXiv},
  eprint = {1702.01715},
  eprinttype = {arxiv},
  file = {/home/oblivion/Zotero/storage/TWP32WT5/Henderson - 2020 - Software Engineering at Google.pdf;/home/oblivion/Zotero/storage/BYJVLKTP/1702.html},
  keywords = {Computer Science - Software Engineering,D.2},
  primaryclass = {cs}
}

@book{hightowerKubernetesRunningDive2017,
  title={Kubernetes: up and running: dive into the future of infrastructure},
  author={Burns, Brendan and Beda, Joe and Hightower, Kelsey},
  year={2019},
  publisher={O'Reilly Media}
}

@online{HippocampalGlobalRemapping,
  title = {Hippocampal {{Global Remapping Can Occur}} without {{Input}} from the {{Medial Entorhinal Cortex}}: {{Cell Reports}}},
  url = {https://www.cell.com/cell-reports/fulltext/S2211-1247(18)30292-4},
  urldate = {2019-06-21},
  file = {/home/oblivion/Zotero/storage/PCU4Z2FP/S2211-1247(18)30292-4.html}
}

@article{hortonCorticalColumnStructure2005,
  title = {The Cortical Column: A Structure without a Function},
  shorttitle = {The Cortical Column},
  author = {Horton, Jonathan C and Adams, Daniel L},
  year = 2005,
  journaltitle = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  shortjournal = {Philos Trans R Soc Lond B Biol Sci},
  volume = {360},
  pages = {837--862},
  issn = {0962-8436},
  doi = {10.1098/rstb.2005.1623},
  abstract = {This year, the field of neuroscience celebrates the 50th anniversary of Mountcastle's discovery of the cortical column. In this review, we summarize half a century of research and come to the disappointing realization that the column may have no function. Originally, it was described as a discrete structure, spanning the layers of the somatosensory cortex, which contains cells responsive to only a single modality, such as deep joint receptors or cutaneous receptors. Subsequently, examples of columns have been uncovered in numerous cortical areas, expanding the original concept to embrace a variety of different structures and principles. A ‘column’ now refers to cells in any vertical cluster that share the same tuning for any given receptive field attribute. In striate cortex, for example, cells with the same eye preference are grouped into ocular dominance columns. Unaccountably, ocular dominance columns are present in some species, but not others. In principle, it should be possible to determine their function by searching for species differences in visual performance that correlate with their presence or absence. Unfortunately, this approach has been to no avail; no visual faculty has emerged that appears to require ocular dominance columns. Moreover, recent evidence has shown that the expression of ocular dominance columns can be highly variable among members of the same species, or even in different portions of the visual cortex in the same individual. These observations deal a fatal blow to the idea that ocular dominance columns serve a purpose. More broadly, the term ‘column’ also denotes the periodic termination of anatomical projections within or between cortical areas. In many instances, periodic projections have a consistent relationship with some architectural feature, such as the cytochrome oxidase patches in V1 or the stripes in V2. These tissue compartments appear to divide cells with different receptive field properties into distinct processing streams. However, it is unclear what advantage, if any, is conveyed by this form of columnar segregation. Although the column is an attractive concept, it has failed as a unifying principle for understanding cortical function. Unravelling the organization of the cerebral cortex will require a painstaking description of the circuits, projections and response properties peculiar to cells in each of its various areas.},
  eprint = {15937015},
  eprinttype = {pmid},
  file = {/home/oblivion/Zotero/storage/LT5J6VME/Horton and Adams - 2005 - The cortical column a structure without a functio.pdf},
  number = {1456},
  pmcid = {PMC1569491}
}

@online{iannarioGettingStartedDrupal2019,
  title = {Getting Started with {{Drupal}} 8 on {{Kubernetes}}},
  author = {Iannario, Luca},
  date = {2019-07-19T17:23:57},
  url = {https://medium.com/faun/getting-started-with-drupal-8-on-kubernetes-4d9086473848},
  urldate = {2019-08-28},
  abstract = {This is tutorial to deploy a new Drupal Website on a Kubernetes cluster hosted on Oracle Container Engine (OKE)},
  file = {/home/oblivion/Zotero/storage/BVUNIU2C/getting-started-with-drupal-8-on-kubernetes-4d9086473848.html},
  langid = {english},
  organization = {{Medium}}
}

@software{innesLazyJl,
  title = {Lazy.Jl},
  author = {Innes, Mike},
  url = {https://github.com/MikeInnes/Lazy.jl},
  urldate = {2019-06-04}
}

@inproceedings{islamAnomalyDetectionCloud2020,
  title = {Anomaly {{Detection}} in {{Cloud Components}}},
  booktitle = {2020 {{IEEE}} 13th {{International Conference}} on {{Cloud Computing}} ({{CLOUD}})},
  author = {Islam, M. S. and Miranskyy, A.},
  year = 2020,
  pages = {1--3},
  issn = {2159-6190},
  doi = {10.1109/CLOUD49709.2020.00008},
  abstract = {Cloud platforms, under the hood, consist of a complex inter-connected stack of hardware and software components. Each of these components can fail which may lead to an outage. Our goal is to improve the quality of Cloud services through early detection of such failures by analyzing resource utilization metrics. We tested Gated-Recurrent-Unit-based autoencoder with a likelihood function to detect anomalies in various multidimensional time series and achieved high performance.},
  eventtitle = {2020 {{IEEE}} 13th {{International Conference}} on {{Cloud Computing}} ({{CLOUD}})},
  file = {/home/oblivion/Zotero/storage/N8UM7PVN/Islam and Miranskyy - 2020 - Anomaly Detection in Cloud Components.pdf;/home/oblivion/Zotero/storage/SSHZMHZW/9284273.html},
  keywords = {anomaly detection,Anomaly detection,cloud components,Cloud computing,machine learning,Monitoring,Resource management,Software,Telemetry,time series,Time series analysis}
}

@inproceedings{jarvinenExtendingKubernetesOperator2019,
  title={Extending Kubernetes with the Operator Pattern},
  author={Jarvinen, Ryan},
  year={2019}
}

@article{jaukRelationshipIntelligenceCreativity2013,
  title = {The Relationship between Intelligence and Creativity: {{New}} Support for the Threshold Hypothesis by Means of Empirical Breakpoint Detection},
  shorttitle = {The Relationship between Intelligence and Creativity},
  author = {Jauk, Emanuel and Benedek, Mathias and Dunst, Beate and Neubauer, Aljoscha C.},
  year = 2013,
  journaltitle = {Intelligence},
  shortjournal = {Intelligence},
  volume = {41},
  pages = {212--221},
  issn = {0160-2896},
  doi = {10.1016/j.intell.2013.03.003},
  abstract = {The relationship between intelligence and creativity has been subject to empirical research for decades. Nevertheless, there is yet no consensus on how these constructs are related. One of the most prominent notions concerning the interplay between intelligence and creativity is the threshold hypothesis, which assumes that above-average intelligence represents a necessary condition for high-level creativity. While earlier research mostly supported the threshold hypothesis, it has come under fire in recent investigations. The threshold hypothesis is commonly investigated by splitting a sample at a given threshold (e.g., at 120 IQ points) and estimating separate correlations for lower and upper IQ ranges. However, there is no compelling reason why the threshold should be fixed at an IQ of 120, and to date, no attempts have been made to detect the threshold empirically. Therefore, this study examined the relationship between intelligence and different indicators of creative potential and of creative achievement by means of segmented regression analysis in a sample of 297 participants. Segmented regression allows for the detection of a threshold in continuous data by means of iterative computational algorithms. We found thresholds only for measures of creative potential but not for creative achievement. For the former the thresholds varied as a function of criteria: When investigating a liberal criterion of ideational originality (i.e., two original ideas), a threshold was detected at around 100 IQ points. In contrast, a threshold of 120 IQ points emerged when the criterion was more demanding (i.e., many original ideas). Moreover, an IQ of around 85 IQ points was found to form the threshold for a purely quantitative measure of creative potential (i.e., ideational fluency). These results confirm the threshold hypothesis for qualitative indicators of creative potential and may explain some of the observed discrepancies in previous research. In addition, we obtained evidence that once the intelligence threshold is met, personality factors become more predictive for creativity. On the contrary, no threshold was found for creative achievement, i.e. creative achievement benefits from higher intelligence even at fairly high levels of intellectual ability.},
  file = {/home/oblivion/Zotero/storage/85X8IKT4/Jauk et al. - 2013 - The relationship between intelligence and creativi.pdf;/home/oblivion/Zotero/storage/G8VCCFR4/S016028961300024X.html},
  keywords = {*,Breakpoint detection,Creativity,Intelligence,Segmented regression,Threshold hypothesis},
  number = {4}
}

@online{juggeryCloserLookEtcd2019,
  title = {A {{Closer Look}} at {{Etcd}}: {{The Brain}} of a {{Kubernetes Cluster}}},
  shorttitle = {A {{Closer Look}} at {{Etcd}}},
  author = {Juggery, Luc},
  date = {2019-08-14T08:18:26},
  url = {https://medium.com/better-programming/a-closer-look-at-etcd-the-brain-of-a-kubernetes-cluster-788c8ea759a5},
  urldate = {2019-08-28},
  abstract = {What etcd contains and how it organizes information},
  file = {/home/oblivion/Zotero/storage/3RPZXKN6/a-closer-look-at-etcd-the-brain-of-a-kubernetes-cluster-788c8ea759a5.html},
  langid = {english},
  organization = {{Medium}}
}

@book{kandelPrinciplesNeuralScience2013,
  title = {Principles of {{Neural Science}}, {{Fifth Edition}}},
  author = {Kandel, Eric R. and Jessell, Thomas M. and Schwartz, James H. and Siegelbaum, Steven A. and Hudspeth, A. J.},
  year = 2013,
  publisher = {{McGraw Hill Professional}},
  abstract = {Publisher's Note: Products purchased from Third Party sellers are not guaranteed by the publisher for quality, authenticity, or access to any online entitlements included with the product.Now updated: the definitive neuroscience resource—from Eric R. Kandel, MD (winner of the Nobel Prize in 2000); James H. Schwartz, MD, PhD; Thomas M. Jessell, PhD; Steven A. Siegelbaum, PhD; and A. J. Hudspeth, PhDA Doody's Core Title for 2019!900 full-color illustrationsDeciphering the link between the human brain and behavior has always been one of the most intriguing—and often challenging—aspects of scientific endeavor. The sequencing of the human genome, and advances in molecular biology, have illuminated the pathogenesis of many neurological diseases and have propelled our knowledge of how the brain controls behavior.To grasp the wider implications of these developments and gain a fundamental understanding of this dynamic, fast-moving field, Principles of Neuroscience stands alone as the most authoritative and indispensible resource of its kind.In this classic text, prominent researchers in the field expertly survey the entire spectrum of neural science, giving an up-to-date, unparalleled view of the discipline for anyone who studies brain and mind. Here, in one remarkable volume, is the current state of neural science knowledge—ranging from molecules and cells, to anatomic structures and systems, to the senses and cognitive functions—all supported by more than 900 precise, full-color illustrations. In addition to clarifying complex topics, the book also benefits from a cohesive organization, beginning with an insightful overview of the interrelationships between the brain, nervous system, genes, and behavior. Principles of Neural Science then proceeds with an in-depth examination of the molecular and cellular biology of nerve cells, synaptic transmission, and the neural basis of cognition. The remaining sections illuminate how cells, molecules, and systems give us sight, hearing, touch, movement, thought, learning, memories, and emotions.The new fifth edition of Principles of Neural Science is thoroughly updated to reflect the tremendous amount of research, and the very latest clinical perspectives, that have significantly transformed the field within the last decade.Ultimately, Principles of Neural Science affirms that all behavior is an expression of neural activity, and that the future of clinical neurology and psychiatry hinges on the progress of neural science. Far exceeding the scope and scholarship of similar texts, this unmatched guide offers a commanding, scientifically rigorous perspective on the molecular mechanisms of neural function and disease—one that you’ll continually rely on to advance your comprehension of brain, mind, and behavior.FEATURESThe cornerstone reference in the field of neuroscience that explains how the nerves, brain, and mind functionClear emphasis on how behavior can be examined through the electrical activity of both individual neurons and systems of nerve cellsCurrent focus on molecular biology as a tool for probing the pathogenesis of many neurological diseases, including muscular dystrophy, Huntington disease, and certain forms of Alzheimer’s diseaseMore than 900 engaging full-color illustrations—including line drawings, radiographs, micrographs, and medical photographs clarify often-complex neuroscience conceptsOutstanding section on the development and emergence of behavior, including important coverage of},
  isbn = {978-0-07-139011-8},
  keywords = {Medical / Neurology,Medical / Neuroscience,Science / Life Sciences / Neuroscience},
  langid = {english},
  pagetotal = {1761}
}

@article{kardani-moghaddamPerformanceAnomalyDetection2019,
  title = {Performance Anomaly Detection Using Isolation‐trees in Heterogeneous Workloads of Web Applications in Computing Clouds},
  author = {Kardani-Moghaddam, Sara and Buyya, R. and Ramamohanarao, K.},
  year = 2019,
  journaltitle = {Concurr. Comput. Pract. Exp.},
  doi = {10.1002/cpe.5306},
  abstract = {Cloud computing is a model for on‐demand access to shared resources based on the pay‐per‐use policy. In order to efficiently manage the resources, a continuous analysis of the operational state of the system is required to be able to detect the performance degradations and malfunctioned resources as soon as possible. Every change in the workload, hardware condition, or software code can change the state of the system from normal to abnormal, which causes the performance and quality of service degradations. These changes or anomalies vary from a simple gradual increase in the load to flash crowds, hardware faults, software bugs, etc. In this paper, we propose Isolation‐Forest based anomaly detection (IFAD) framework based on the unsupervised Isolation technique for anomaly detection in a multi‐attribute space of performance indicators for web‐based applications. Unsupervised nature of the algorithm and its fast execution make this algorithm most suitable for the environments with dynamic nature where the patterns of data change frequently. The experiment results demonstrate that IFAD can achieve good detection accuracy especially in terms of precision for multiple types of the anomaly. Moreover, we show the importance of validating the accuracy of anomaly detection algorithms with regard to both Area Under the Curve (AUC) and Precision‐Recall AUC (PRAUC) in an extensive set of comparisons including multiple unsupervised algorithms. The demonstration of the effectiveness of each algorithm shown by PRAUC results indicates the importance of PRAUC in selecting suitable anomaly detection algorithm, which is largely ignored in the literature.},
  file = {/home/oblivion/Zotero/storage/BGZS458U/Kardani-Moghaddam et al. - 2019 - Performance anomaly detection using isolation‐tree.pdf},
  keywords = {p1}
}

@inproceedings{kavianiServerlessCommodityCase2019,
  title = {Towards {{Serverless}} as {{Commodity}}: A Case of {{Knative}}},
  shorttitle = {Towards {{Serverless}} as {{Commodity}}},
  booktitle = {{{WOSC}}@{{Middleware}}},
  author = {Kaviani, N. and Kalinin, D. and Maximilien, E.},
  year = 2019,
  doi = {10.1145/3366623.3368135},
  abstract = {Serverless computing promises to evolve cloud computing architecture from VMs and containers-as-a-service (CaaS) to function-as-a-service (FaaS). This takes away complexities of managing and scaling underlying infrastructure and can result in simpler code, cheaper realization of services, and higher availability. Nonetheless, one of the primary drawbacks customers face when making decision to move their software to a serverless platform is the potential for getting locked-in with a particular provider. This used to be a concern with Platform-as-a-Service (PaaS) offerings too. However with Kubernetes emerging as the industry standard PaaS layer, PaaS is closer to becoming commodity with the Kubernetes API as its common interface. The question is if a similar unification for the API interface layer and runtime contracts can be achieved for serverless. If achieved, this would free up serverless users from their fears of platform lock-in. Our goal in this paper is to extract a minimal common denominator model of execution that can move us closer to a unified serverless platform. As contributors to Knative [13] with in-depth understanding of its internal design, we use Knative as the baseline for this comparison and contrast its API interface and runtime contracts against other prominent serverless platforms to identify commonalities and differences. Influenced by the work in Knative, we also discuss challenges as well as the necessary evolution we expect to see as serverless platforms themselves reach commodity status.}
}

@inproceedings{kavianiServerlessCommodityCase2019a,
  title = {Towards {{Serverless}} as {{Commodity}}: A Case of {{Knative}}},
  shorttitle = {Towards {{Serverless}} as {{Commodity}}},
  booktitle = {Proceedings of the 5th {{International Workshop}} on {{Serverless Computing}}},
  author = {Kaviani, Nima and Kalinin, Dmitriy and Maximilien, Michael},
  year = 2019,
  pages = {13--18},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/3366623.3368135},
  abstract = {Serverless computing promises to evolve cloud computing architecture from VMs and containers-as-a-service (CaaS) to function-as-a-service (FaaS). This takes away complexities of managing and scaling underlying infrastructure and can result in simpler code, cheaper realization of services, and higher availability. Nonetheless, one of the primary drawbacks customers face when making decision to move their software to a serverless platform is the potential for getting locked-in with a particular provider. This used to be a concern with Platform-as-a-Service (PaaS) offerings too. However with Kubernetes emerging as the industry standard PaaS layer, PaaS is closer to becoming commodity with the Kubernetes API as its common interface. The question is if a similar unification for the API interface layer and runtime contracts can be achieved for serverless. If achieved, this would free up serverless users from their fears of platform lock-in. Our goal in this paper is to extract a minimal common denominator model of execution that can move us closer to a unified serverless platform. As contributors to Knative [13] with in-depth understanding of its internal design, we use Knative as the baseline for this comparison and contrast its API interface and runtime contracts against other prominent serverless platforms to identify commonalities and differences. Influenced by the work in Knative, we also discuss challenges as well as the necessary evolution we expect to see as serverless platforms themselves reach commodity status.},
  isbn = {978-1-4503-7038-7},
  keywords = {cloud,performance,scalability,serverless},
  series = {{{WOSC}} '19}
}

@online{KbConnectorZotero,
  title = {Kb:Connector Zotero Unavailable [{{Zotero Documentation}}]},
  url = {https://www.zotero.org/support/kb/connector_zotero_unavailable},
  urldate = {2019-05-28},
  file = {/home/oblivion/Zotero/storage/IMQUVXT4/connector_zotero_unavailable.html}
}

@online{kipouridisConvergenceNetworkSystems2019,
  title = {On the {{Convergence}} of {{Network Systems}}},
  author = {Kipouridis, Evangelos and Tsichlas, Kostas},
  year = 2019,
  url = {http://arxiv.org/abs/1902.04121},
  urldate = {2019-06-10},
  abstract = {The apparent disconnection between the microscopic and the macroscopic is a major issue in the understanding of complex systems. To this extend, we study the convergence of repeatedly applying local rules on a network, and touch on the expressive power of this model. We look at network systems and study their behavior when different types of local rules are applied on them. For a very general class of local rules, we prove convergence and provide a certain member of this class that, when applied on a graph, efficiently computes its k-core and its (k-1)-crust giving hints on the expressive power of such a model. Furthermore, we provide guarantees on the speed of convergence for an important subclass of the aforementioned class. We also study more general rules, and show that they do not converge. Our counterexamples resolve an open question of (Zhang, Wang, Wang, Zhou, KDD- 2009) as well, concerning whether a certain process converges. Finally, we show the universality of our network system, by providing a local rule under which it is Turing-Complete.},
  archiveprefix = {arXiv},
  eprint = {1902.04121},
  eprinttype = {arxiv},
  file = {/home/oblivion/Zotero/storage/PNJVB92B/Kipouridis and Tsichlas - 2019 - On the Convergence of Network Systems.pdf;/home/oblivion/Zotero/storage/3RAIUSPF/1902.html},
  keywords = {Computer Science - Data Structures and Algorithms,F.1.1,F.2.2,G.2.2,Mathematics - Dynamical Systems},
  primaryclass = {cs, math}
}

@article{knuthLiterateProgramming1984,
  title = {Literate {{Programming}}},
  author = {Knuth, D. E.},
  year = 1984,
  journaltitle = {The Computer Journal},
  shortjournal = {Comput J},
  volume = {27},
  pages = {97--111},
  issn = {0010-4620},
  doi = {10.1093/comjnl/27.2.97},
  abstract = {Abstract.  The author and his associates have been experimenting for the past several years with a programming language and documentation system called WEB. Thi},
  file = {/home/oblivion/Zotero/storage/ULZUHH86/Knuth - 1984 - Literate Programming.pdf;/home/oblivion/Zotero/storage/T97AHG7F/343244.html},
  langid = {english},
  number = {2}
}

@article{lanFDNNFeaturebasedDeep2019,
  title = {{{FDNN}}: {{Feature}}-Based {{Deep Neural Network Model}} for {{Anomaly Detection}} of {{KPIs}}},
  shorttitle = {{{FDNN}}},
  author = {Lan, Zhibo and Xu, Liutong and Fang, Wei},
  year = 2019,
  journaltitle = {2019 IEEE 10th International Conference on Software Engineering and Service Science (ICSESS)},
  doi = {10.1109/ICSESS47205.2019.9040841},
  abstract = {Anomaly detection of KPIs (key performance indicators) has been widely applied to guarantee systems stability in real world. KPIs include response time of Web pages, CPU utilization, memory utilization, disk IO and so on. However, time series of different KPIs have different shapes, so that it is a great challenge to detect anomaly of KPIs by a simple statistical or machine learning model. In this paper, we design and implement FDNN (Feature-based Deep Neural Network) model for anomaly detection of KPIs. We present a novel feature engineering approach called MSWFeature (multiple sliding windows feature) which is more suitable to extract temporal feature for time series of KPIs. FDNN model with MSWFeature achieves good performance in F1-Score over other supervised models for anomaly detection on the studied KPIs dataset collected by the top global internet companies. (Abstract)},
  file = {/home/oblivion/Zotero/storage/WSCI6FCX/Lan et al. - 2019 - FDNN Feature-based Deep Neural Network Model for .pdf},
  keywords = {p1}
}

@inproceedings{leggCollectionDefinitionsIntelligence2007,
  title = {A {{Collection}} of {{Definitions}} of {{Intelligence}}},
  booktitle = {Advances in {{Artificial General Intelligence}}: {{Concepts}}, {{Architectures}} and {{Algorithms}}},
  author = {Legg, Shane and Hutter, Marcus},
  year = 2007,
  pages = {17--24},
  publisher = {{IOS Press}},
  eventtitle = {Proceedings of the {{AGI Workshop}}}
}

@article{leggUniversalIntelligenceDefinition2007,
  title = {Universal {{Intelligence}}: {{A Definition}} of {{Machine Intelligence}}},
  shorttitle = {Universal {{Intelligence}}},
  author = {Legg, Shane and Hutter, Marcus},
  year = 2007,
  journaltitle = {Minds and Machines},
  shortjournal = {Minds \& Machines},
  volume = {17},
  pages = {391--444},
  issn = {1572-8641},
  doi = {10.1007/s11023-007-9079-x},
  abstract = {A fundamental problem in artificial intelligence is that nobody really knows what intelligence is. The problem is especially acute when we need to consider artificial systems which are significantly different to humans. In this paper we approach this problem in the following way: we take a number of well known informal definitions of human intelligence that have been given by experts, and extract their essential features. These are then mathematically formalised to produce a general measure of intelligence for arbitrary machines. We believe that this equation formally captures the concept of machine intelligence in the broadest reasonable sense. We then show how this formal definition is related to the theory of universal optimal learning agents. Finally, we survey the many other tests and definitions of intelligence that have been proposed for machines.},
  file = {/home/oblivion/Zotero/storage/3FLW9H64/Legg and Hutter - 2007 - Universal Intelligence A Definition of Machine In.pdf},
  keywords = {AIXI,Complexity theory,Definitions,Intelligence,Intelligence tests,Measures,Theoretical foundations,Turing test},
  langid = {english},
  number = {4}
}

@article{lenatThresholdsKnowledge1991,
  title = {On the Thresholds of Knowledge},
  author = {Lenat, Douglas B. and Feigenbaum, Edward A.},
  year = 1991,
  journaltitle = {Artificial Intelligence},
  shortjournal = {Artificial Intelligence},
  volume = {47},
  pages = {185--250},
  issn = {0004-3702},
  doi = {10.1016/0004-3702(91)90055-O},
  abstract = {We articulate the three major findings and hypotheses of AI to date: 1.(1) The Knowledge Principle: If a program is to perform a complex task well, it must know a great deal about the world in which it operates. In the absence of knowledge, all you have left is search and reasoning, and that isn't enough.2.(2) The Breadth Hypothesis: To behave intelligently in unexpected situations, an agent must be capable of falling back on increasingly general knowledge and analogizing to specific but superficially far-flung knowledge. (This is an extension of the preceding principle.)3.(3) AI as Empirical Inquiry: Premature mathematization, or focusing on toy problems, washes out details from reality that later turn out to be significant. Thus, we must test our ideas experimentally, falsifiably, on large problems. We present evidence for these propositions, contrast them with other strategic approaches to AI, point out their scope and limitations, and discuss the future directions they mandate for the main enterprise of AI research.},
  file = {/home/oblivion/Zotero/storage/Q7Y6YDYK/000437029190055O.html},
  number = {1}
}

@article{liBiHPTMEffectiveSemantic2020,
  title = {Bi-{{HPTM}}: {{An Effective Semantic Matchmaking Model}} for {{Web Service Discovery}}},
  shorttitle = {Bi-{{HPTM}}},
  author = {Li, Shuangyin and Luo, Haoyu and Zhao, Gansen},
  year = 2020,
  journaltitle = {2020 IEEE International Conference on Web Services (ICWS)},
  doi = {10.1109/ICWS49710.2020.00064},
  abstract = {Analyzing textual semantics in matching user query and service description is critical for Web service discovery. Existing works mostly extract the features of the description and query independently, downgrading them into word-level calculation, which can not jointly extract the accurate semantics. For this issue, this work explores a way to enable the semantic matching for the contents (including words, phrases, or sentences) in query and the sentences in service description, by mapping words and sentences into the same semantic space. Specifically, we propose an unsupervised Bayesian probabilistic model, bi-Directional Hybrid Priors Topic Model (bi-HPTM), to capture the textual semantics of the words and sentences in a probabilistic simplex, which provides a flexible operation to build the semantic links from the queries to service descriptions. Meanwhile, the textual semantics generated by bi-HPTM is highly interpretable that help to understand the user requirements. The proposed model is examined by ProgrammableWeb. Experimental results demonstrate that bi-HPTM outperforms state-of-the-art methods for semantic service discovery on service classification and retrieval. The visualizations of the nearest-neighbored queries and descriptions show the insights of our model on capturing the latent semantics of Web services.}
}

@article{losingIncrementalOnlineLearning2018,
  title = {Incremental On-Line Learning: {{A}} Review and Comparison of State of the Art Algorithms},
  shorttitle = {Incremental On-Line Learning},
  author = {Losing, Viktor and Hammer, Barbara and Wersing, Heiko},
  year = 2018,
  journaltitle = {Neurocomputing},
  shortjournal = {Neurocomputing},
  volume = {275},
  pages = {1261--1274},
  issn = {0925-2312},
  doi = {10.1016/j.neucom.2017.06.084},
  abstract = {Recently, incremental and on-line learning gained more attention especially in the context of big data and learning from data streams, conflicting with the traditional assumption of complete data availability. Even though a variety of different methods are available, it often remains unclear which of them is suitable for a specific task and how they perform in comparison to each other. We analyze the key properties of eight popular incremental methods representing different algorithm classes. Thereby, we evaluate them with regards to their on-line classification error as well as to their behavior in the limit. Further, we discuss the often neglected issue of hyperparameter optimization specifically for each method and test how robustly it can be done based on a small set of examples. Our extensive evaluation on data sets with different characteristics gives an overview of the performance with respect to accuracy, convergence speed as well as model complexity, facilitating the choice of the best method for a given application.},
  file = {/home/oblivion/Zotero/storage/YIQA9CEC/Losing et al. - 2018 - Incremental on-line learning A review and compari.pdf;/home/oblivion/Zotero/storage/SRZ5S4GC/S0925231217315928.html},
  keywords = {Data streams,Hyperparameter optimization,Incremental learning,Model selection,On-line learning}
}

@article{maAutoMAPDiagnoseYour2020,
  title = {{{AutoMAP}}: {{Diagnose Your Microservice}}-Based {{Web Applications Automatically}}},
  shorttitle = {{{AutoMAP}}},
  author = {Ma, Meng and Xu, Jingmin and Wang, Yuan and Chen, Pengfei and Zhang, Zonghua and Wang, Ping},
  year = 2020,
  journaltitle = {WWW},
  doi = {10.1145/3366423.3380111},
  abstract = {The high complexity and dynamics of the microservice architecture make its application diagnosis extremely challenging. Static troubleshooting approaches may fail to obtain reliable model applies for frequently changing situations. Even if we know the calling dependency of services, we lack a more dynamic diagnosis mechanism due to the existence of indirect fault propagation. Besides, algorithm based on single metric usually fail to identify the root cause of anomaly, as single type of metric is not enough to characterize the anomalies occur in diverse services. In view of this, we design a novel tool, named AutoMAP, which enables dynamic generation of service correlations and automated diagnosis leveraging multiple types of metrics. In AutoMAP, we propose the concept of anomaly behavior graph to describe the correlations between services associated with different types of metrics. Two binary operations, as well as a similarity function on behavior graph are defined to help AutoMAP choose appropriate diagnosis metric in any particular scenario. Following the behavior graph, we design a heuristic investigation algorithm by using forward, self, and backward random walk, with an objective to identify the root cause services. To demonstrate the strengths of AutoMAP, we develop a prototype and evaluate it in both simulated environment and real-work enterprise cloud system. Experimental results clearly indicate that AutoMAP achieves over 90\% precision, which significantly outperforms other selected baseline methods. AutoMAP can be quickly deployed in a variety of microservice-based systems without any system knowledge. It also supports introduction of various expert knowledge to improve accuracy.},
  keywords = {p2}
}

@article{markramReconstructionSimulationNeocortical2015,
  title = {Reconstruction and {{Simulation}} of {{Neocortical Microcircuitry}}},
  author = {Markram, Henry and Muller, Eilif and Ramaswamy, Srikanth and Reimann, Michael W. and Abdellah, Marwan and Sanchez, Carlos Aguado and Ailamaki, Anastasia and Alonso-Nanclares, Lidia and Antille, Nicolas and Arsever, Selim and Kahou, Guy Antoine Atenekeng and Berger, Thomas K. and Bilgili, Ahmet and Buncic, Nenad and Chalimourda, Athanassia and Chindemi, Giuseppe and Courcol, Jean-Denis and Delalondre, Fabien and Delattre, Vincent and Druckmann, Shaul and Dumusc, Raphael and Dynes, James and Eilemann, Stefan and Gal, Eyal and Gevaert, Michael Emiel and Ghobril, Jean-Pierre and Gidon, Albert and Graham, Joe W. and Gupta, Anirudh and Haenel, Valentin and Hay, Etay and Heinis, Thomas and Hernando, Juan B. and Hines, Michael and Kanari, Lida and Keller, Daniel and Kenyon, John and Khazen, Georges and Kim, Yihwa and King, James G. and Kisvarday, Zoltan and Kumbhar, Pramod and Lasserre, Sébastien and Le Bé, Jean-Vincent and Magalhães, Bruno R. C. and Merchán-Pérez, Angel and Meystre, Julie and Morrice, Benjamin Roy and Muller, Jeffrey and Muñoz-Céspedes, Alberto and Muralidhar, Shruti and Muthurasa, Keerthan and Nachbaur, Daniel and Newton, Taylor H. and Nolte, Max and Ovcharenko, Aleksandr and Palacios, Juan and Pastor, Luis and Perin, Rodrigo and Ranjan, Rajnish and Riachi, Imad and Rodríguez, José-Rodrigo and Riquelme, Juan Luis and Rössert, Christian and Sfyrakis, Konstantinos and Shi, Ying and Shillcock, Julian C. and Silberberg, Gilad and Silva, Ricardo and Tauheed, Farhan and Telefont, Martin and Toledo-Rodriguez, Maria and Tränkler, Thomas and Van Geit, Werner and Díaz, Jafet Villafranca and Walker, Richard and Wang, Yun and Zaninetta, Stefano M. and DeFelipe, Javier and Hill, Sean L. and Segev, Idan and Schürmann, Felix},
  year = 2015,
  journaltitle = {Cell},
  shortjournal = {Cell},
  volume = {163},
  pages = {456--492},
  issn = {1097-4172},
  doi = {10.1016/j.cell.2015.09.029},
  abstract = {We present a first-draft digital reconstruction of the microcircuitry of somatosensory cortex of juvenile rat. The reconstruction uses cellular and synaptic organizing principles to algorithmically reconstruct detailed anatomy and physiology from sparse experimental data. An objective anatomical method defines a neocortical volume of 0.29 ± 0.01 mm(3) containing \textasciitilde 31,000 neurons, and patch-clamp studies identify 55 layer-specific morphological and 207 morpho-electrical neuron subtypes. When digitally reconstructed neurons are positioned in the volume and synapse formation is restricted to biological bouton densities and numbers of synapses per connection, their overlapping arbors form \textasciitilde 8 million connections with \textasciitilde 37 million synapses. Simulations reproduce an array of in vitro and in vivo experiments without parameter tuning. Additionally, we find a spectrum of network states with a sharp transition from synchronous to asynchronous activity, modulated by physiological mechanisms. The spectrum of network states, dynamically reconfigured around this transition, supports diverse information processing strategies. PAPERCLIP: VIDEO ABSTRACT.},
  eprint = {26451489},
  eprinttype = {pmid},
  keywords = {Algorithms,Animals,Computer Simulation,Hindlimb,Male,Models; Neurological,Neocortex,Nerve Net,Neurons,Rats,Rats; Wistar,Somatosensory Cortex},
  langid = {english},
  number = {2}
}

@inproceedings{meginoUsingKubernetesATLAS2020,
  title = {Using {{Kubernetes}} as an {{ATLAS}} Computing Site},
  author = {Megino, F. B. and Donell, D. M. M. and Seuster, R. and Taylor, R. P. and Berghaus, F. and Maeno, T. and Albert, J. and De, K. and Lin, F. and Rocha, R. B. D. and Yang, Ming-Jyuan},
  year = 2020,
  doi = {10.1051/epjconf/202024507025},
  abstract = {In recent years containerization has revolutionized cloud environments, providing a secure, lightweight, standardized way to package and execute software. Solutions such as Kubernetes enable orchestration of containers in a cluster, including for the purpose of job scheduling. Kubernetes is becoming a de facto standard, available at all major cloud computing providers, and is gaining increased attention from some WLCG sites. In particular, CERN IT has integrated Kubernetes into their cloud infrastructure by providing an interface to instantly create Kubernetes clusters, and the University of Victoria is pursuing an infrastructure-as-code approach to deploying Kubernetes as a flexible and resilient platform for running services and delivering resources.The ATLAS experiment at the LHC has partnered with CERN IT and the University of Victoria to explore and demonstrate the feasibility of running an ATLAS computing site directly on Kubernetes, replacing all grid computing services. We have interfaced ATLAS’ workload submission engine PanDA with Kubernetes, to directly submit and monitor the status of containerized jobs. We describe the integration and deployment details, and focus on the lessons learned from running a wide variety of ATLAS production payloads on Kubernetes using clusters of several thousand cores at CERN and the Tier 2 computing site in Victoria.},
  file = {/home/oblivion/Zotero/storage/LD4BTDC4/Megino et al. - 2020 - Using Kubernetes as an ATLAS computing site.pdf}
}

@article{meginoUsingKubernetesATLAS2020a,
  title = {Using {{Kubernetes}} as an {{ATLAS}} Computing Site},
  author = {Megino, Fernando Harald Barreiro and Albert, Jeffrey Ryan and Berghaus, Frank and De, Kaushik and Lin, FaHui and MacDonell, Danika and Maeno, Tadashi and Rocha, Ricardo Brito Da and Seuster, Rolf and Taylor, Ryan Paul and Yang, Ming-Jyuan},
  year = 2020,
  journaltitle = {EPJ Web of Conferences},
  shortjournal = {EPJ Web Conf.},
  volume = {245},
  pages = {07025},
  publisher = {{EDP Sciences}},
  issn = {2100-014X},
  doi = {10.1051/epjconf/202024507025},
  abstract = {In recent years containerization has revolutionized cloud environments, providing a secure, lightweight, standardized way to package and execute software. Solutions such as Kubernetes enable orchestration of containers in a cluster, including for the purpose of job scheduling. Kubernetes is becoming a de facto standard, available at all major cloud computing providers, and is gaining increased attention from some WLCG sites. In particular, CERN IT has integrated Kubernetes into their cloud infrastructure by providing an interface to instantly create Kubernetes clusters, and the University of Victoria is pursuing an infrastructure-as-code approach to deploying Kubernetes as a flexible and resilient platform for running services and delivering resources.The ATLAS experiment at the LHC has partnered with CERN IT and the University of Victoria to explore and demonstrate the feasibility of running an ATLAS computing site directly on Kubernetes, replacing all grid computing services. We have interfaced ATLAS’ workload submission engine PanDA with Kubernetes, to directly submit and monitor the status of containerized jobs. We describe the integration and deployment details, and focus on the lessons learned from running a wide variety of ATLAS production payloads on Kubernetes using clusters of several thousand cores at CERN and the Tier 2 computing site in Victoria.},
  file = {/home/oblivion/Zotero/storage/29WGWIUX/Megino et al. - 2020 - Using Kubernetes as an ATLAS computing site.pdf;/home/oblivion/Zotero/storage/BJ6MZ62A/epjconf_chep2020_07025.html},
  langid = {english}
}

@inproceedings{meierMixedsignalUniversalNeuromorphic2015,
  title = {A Mixed-Signal Universal Neuromorphic Computing System},
  booktitle = {2015 {{IEEE International Electron Devices Meeting}} ({{IEDM}})},
  author = {Meier, K.},
  year = 2015,
  pages = {4.6.1-4.6.4},
  doi = {10.1109/IEDM.2015.7409627},
  abstract = {Neuromorphic information processing systems offer the potential to overcome imminent problems of state-of-the-art computers, in particular the energy efficiency problem, the device reliability problem and the software complexity problem. This paper starts with a short overview of state-of-the-art neuromorphic hardware implementations and their applications. It then describes the time-accelerated mixed-signal approach of the BrainScaleS project in some detail.},
  eventtitle = {2015 {{IEEE International Electron Devices Meeting}} ({{IEDM}})},
  file = {/home/oblivion/Zotero/storage/TJQKNNXI/7409627.html},
  keywords = {Biological system modeling,Brain modeling,BrainScaleS project,Computational modeling,device reliability problem,Energy efficiency,energy efficiency problem,mixed-signal universal neuromorphic computing system,neural net architecture,neuromorphic hardware implementations,neuromorphic information processing systems,Neuromorphics,Neurons,power aware computing,software complexity problem,software metrics,time-accelerated mixed-signal approach,VLSI}
}

@book{minskySocietyMind1988,
  title = {Society {{Of Mind}}},
  author = {Minsky, Marvin},
  year = 1988,
  publisher = {{Simon and Schuster}},
  abstract = {Marvin Minsky -- one of the fathers of computer science and cofounder of the Artificial Intelligence Laboratory at MIT -- gives a revolutionary answer to the age-old question: "How does the mind work?"  Minsky brilliantly portrays the mind as a "society" of tiny components that are themselves mindless. Mirroring his theory, Minsky boldly casts The Society of Mind as an intellectual puzzle whose pieces are assembled along the way. Each chapter -- on a self-contained page -- corresponds to a piece in the puzzle. As the pages turn, a unified theory of the mind emerges, like a mosaic. Ingenious, amusing, and easy to read, The Society of Mind is an adventure in imagination.},
  eprint = {bLDLllfRpdkC},
  eprinttype = {googlebooks},
  isbn = {978-0-671-65713-0},
  keywords = {Psychology / Cognitive Psychology & Cognition,Science / General,Science / Philosophy & Social Aspects},
  langid = {english},
  pagetotal = {342}
}

@article{mohammadiAutomatedDesignSynthetic2017,
  title = {Automated {{Design}} of {{Synthetic Cell Classifier Circuits Using}} a {{Two}}-{{Step Optimization Strategy}}},
  author = {Mohammadi, Pejman and Beerenwinkel, Niko and Benenson, Yaakov},
  year = 2017,
  journaltitle = {Cell Systems},
  shortjournal = {cels},
  volume = {4},
  pages = {207-218.e14},
  issn = {2405-4712},
  doi = {10.1016/j.cels.2017.01.003},
  abstract = {{$<$}h2{$>$}Summary{$<$}/h2{$><$}p{$>$}Cell classifiers are genetic logic circuits that transduce endogenous molecular inputs into cell-type-specific responses. Designing classifiers that achieve optimal differential response between specific cell types is a hard computational problem because it involves selection of endogenous inputs and optimization of both biochemical parameters and a logic function. To address this problem, we first derive an optimal set of biochemical parameters with the largest expected differential response over a diverse set of logic circuits, and second, we use these parameters in an evolutionary algorithm to select circuit inputs and optimize the logic function. Using this approach, we design experimentally feasible microRNA-based circuits capable of perfect discrimination for several real-world cell-classification tasks. We also find that under realistic cell-to-cell variation, circuit performance is comparable to standard cross-validation performance estimates. Our approach facilitates the generation of candidate circuits for experimental testing in therapeutic settings that require precise cell targeting, such as cancer therapy.{$<$}/p{$>$}},
  eprint = {28189580},
  eprinttype = {pmid},
  file = {/home/oblivion/Zotero/storage/2LVBESA3/Mohammadi, Beerenwinkel, Benenson - Automated design of Synthetic Cell Classifier Circuits - Cell (2017).pdf;/home/oblivion/Zotero/storage/WALF44TP/Mohammadi et al. - 2017 - Automated Design of Synthetic Cell Classifier Circ.pdf;/home/oblivion/Zotero/storage/6FU6P2XH/S2405-4712(17)30003-0.html},
  langid = {english},
  number = {2}
}

@article{mohammadiDeepLearningIoT2018,
  title = {Deep {{Learning}} for {{IoT Big Data}} and {{Streaming Analytics}}: {{A Survey}}},
  shorttitle = {Deep {{Learning}} for {{IoT Big Data}} and {{Streaming Analytics}}},
  author = {Mohammadi, M. and Al-Fuqaha, A. and Sorour, S. and Guizani, M.},
  year = {Fourthquarter 2018},
  journaltitle = {IEEE Communications Surveys Tutorials},
  volume = {20},
  pages = {2923--2960},
  issn = {1553-877X},
  doi = {10.1109/COMST.2018.2844341},
  abstract = {In the era of the Internet of Things (IoT), an enormous amount of sensing devices collect and/or generate various sensory data over time for a wide range of fields and applications. Based on the nature of the application, these devices will result in big or fast/real-time data streams. Applying analytics over such data streams to discover new information, predict future insights, and make control decisions is a crucial process that makes IoT a worthy paradigm for businesses and a quality-of-life improving technology. In this paper, we provide a thorough overview on using a class of advanced machine learning techniques, namely deep learning (DL), to facilitate the analytics and learning in the IoT domain. We start by articulating IoT data characteristics and identifying two major treatments for IoT data from a machine learning perspective, namely IoT big data analytics and IoT streaming data analytics. We also discuss why DL is a promising approach to achieve the desired analytics in these types of data and applications. The potential of using emerging DL techniques for IoT data analytics are then discussed, and its promises and challenges are introduced. We present a comprehensive background on different DL architectures and algorithms. We also analyze and summarize major reported research attempts that leveraged DL in the IoT domain. The smart IoT devices that have incorporated DL in their intelligence background are also discussed. DL implementation approaches on the fog and cloud centers in support of IoT applications are also surveyed. Finally, we shed light on some challenges and potential directions for future research. At the end of each section, we highlight the lessons learned based on our experiments and review of the recent literature.},
  file = {/home/oblivion/Zotero/storage/BRC33E2W/Mohammadi et al. - 2018 - Deep Learning for IoT Big Data and Streaming Analy.pdf;/home/oblivion/Zotero/storage/J9WWJHR8/8373692.html},
  keywords = {advanced machine learning techniques,Big Data,cloud centers,cloud-based analytics,data analysis,Data analysis,Data mining,deep learning,Deep learning,deep neural network,DL implementation,Economics,fast data analytics,fast/real-time data streams,fog centers,Internet of Things,IoT applications,IoT big data,IoT big data analytics,IoT data characteristics,IoT domain,learning (artificial intelligence),Machine learning,machine learning perspective,on-device intelligence,quality-of-life,sensory data,smart IoT devices,streaming analytics,Tutorials},
  number = {4}
}

@article{mountcastleColumnarOrganizationNeocortex1997,
  title = {The Columnar Organization of the Neocortex},
  author = {Mountcastle, V. B.},
  year = 1997,
  journaltitle = {Brain: A Journal of Neurology},
  shortjournal = {Brain},
  volume = {120 ( Pt 4)},
  pages = {701--722},
  issn = {0006-8950},
  doi = {10.1093/brain/120.4.701},
  abstract = {The modular organization of nervous systems is a widely documented principle of design for both vertebrate and invertebrate brains of which the columnar organization of the neocortex is an example. The classical cytoarchitectural areas of the neocortex are composed of smaller units, local neural circuits repeated iteratively within each area. Modules may vary in cell type and number, in internal and external connectivity, and in mode of neuronal processing between different large entities; within any single large entity they have a basic similarity of internal design and operation. Modules are most commonly grouped into entities by sets of dominating external connections. This unifying factor is most obvious for the heterotypical sensory and motor areas of the neocortex. Columnar defining factors in homotypical areas are generated, in part, within the cortex itself. The set of all modules composing such an entity may be fractionated into different modular subsets by different extrinsic connections. Linkages between them and subsets in other large entities form distributed systems. The neighborhood relations between connected subsets of modules in different entities result in nested distributed systems that serve distributed functions. A cortical area defined in classical cytoarchitectural terms may belong to more than one and sometimes to several distributed systems. Columns in cytoarchitectural areas located at some distance from one another, but with some common properties, may be linked by long-range, intracortical connections.},
  eprint = {9153131},
  eprinttype = {pmid},
  file = {/home/oblivion/Zotero/storage/LMG4MQC8/Mountcastle - 1997 - The columnar organization of the neocortex.pdf},
  keywords = {Animals,Brain Mapping,Cell Division,Cell Movement,Cerebral Cortex,Humans,Models; Neurological,Neurons},
  langid = {english}
}

@article{mukherjeeRADDetectingPerformance2020,
  title = {{{RAD}}: {{Detecting Performance Anomalies}} in {{Cloud}}-Based {{Web Services}}},
  shorttitle = {{{RAD}}},
  author = {Mukherjee, Joydeep and Baluta, Alexandru and Litoiu, M. and Krishnamurthy, Diwakar},
  year = 2020,
  journaltitle = {2020 IEEE 13th International Conference on Cloud Computing (CLOUD)},
  doi = {10.1109/CLOUD49709.2020.00073},
  abstract = {Web services hosted on public cloud platforms are often subjected to performance anomalies. Runtime detection of such anomalies is crucial for operations in cloud data centers. With ever-increasing data center size, complexities in software applications and dynamic traffic workload patterns, automatically detecting performance anomalies is a challenging task. In this paper, we propose RAD, a lightweight runtime anomaly detection technique that does not require application level instrumentation and can be easily implemented for detecting anomalies in multi-tier cloud-based Web services. In particular, we focus on anomalies that are difficult to detect by simply monitoring system level metrics alone, such as anomalies that are caused by contention from within a service and also those caused by shared resource contention by other services running on the cloud. RAD continuously monitors service resource metrics and uses a queuing network model to detect performance anomalies at runtime. Additionally, RAD uses historical data and implements a statistical methodology to diagnose the root cause of an anomaly. We evaluate RAD on a private cloud and also on the EC2 public cloud platform to show that RAD incurs extremely low levels of performance overhead on the service and is effective for detecting anomalies in both multi-tier monolithic services and microservices.},
  keywords = {p2}
}

@incollection{nachumDataEfficientHierarchicalReinforcement2018,
  title = {Data-{{Efficient Hierarchical Reinforcement Learning}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 31},
  author = {Nachum, Ofir and Gu, Shixiang (Shane) and Lee, Honglak and Levine, Sergey},
  editor = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and Cesa-Bianchi, N. and Garnett, R.},
  year = 2018,
  pages = {3303--3313},
  publisher = {{Curran Associates, Inc.}},
  url = {http://papers.nips.cc/paper/7591-data-efficient-hierarchical-reinforcement-learning.pdf},
  urldate = {2019-05-30},
  file = {/home/oblivion/Zotero/storage/Q3L8PUJL/Nachum et al. - 2018 - Data-Efficient Hierarchical Reinforcement Learning.pdf;/home/oblivion/Zotero/storage/7BTHX96C/7591-data-efficient-hierarchical-reinforcement-learning.html}
}

@article{naikadeAutomatedAnomalyDetection2020,
  title = {Automated {{Anomaly Detection}} and {{Localization System}} for a {{Microservices Based Cloud System}}},
  author = {Naikade, Priyanka},
  year = 2020,
  journaltitle = {Electronic Thesis and Dissertation Repository},
  url = {https://ir.lib.uwo.ca/etd/7109},
  file = {/home/oblivion/Zotero/storage/UX36P9SU/7109.html}
}

@software{numentaNUPIC,
  title = {{{NUPIC}}},
  author = {Numenta},
  url = {https://github.com/numenta/nupic},
  urldate = {2019-06-04}
}

@software{numentaNuPICHotGymPrediction2019,
  title = {{{NuPIC}} - {{HotGym Prediction}}},
  shorttitle = {Numenta {{Platform}} for {{Intelligent Computing}} Is an Implementation of {{Hierarchical Temporal Memory}} ({{HTM}}), a Theory of Intelligence Based Strictly on the Neuroscience of the Neocortex.},
  author = {Numenta},
  date = {2019-06-04T01:30:58Z},
  origdate = {2013-04-05T23:14:27Z},
  url = {https://github.com/numenta/nupic/tree/master/examples/opf/clients/hotgym/prediction/one_gym},
  urldate = {2019-06-10},
  organization = {{Numenta}}
}

@article{papadimitriouBrainComputationAssemblies2020,
  title = {Brain Computation by Assemblies of Neurons},
  author = {Papadimitriou, Christos H. and Vempala, Santosh S. and Mitropolsky, Daniel and Collins, Michael and Maass, Wolfgang},
  year = 2020,
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {PNAS},
  volume = {117},
  pages = {14464--14472},
  publisher = {{National Academy of Sciences}},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.2001893117},
  abstract = {Assemblies are large populations of neurons believed to imprint memories, concepts, words, and other cognitive information. We identify a repertoire of operations on assemblies. These operations correspond to properties of assemblies observed in experiments, and can be shown, analytically and through simulations, to be realizable by generic, randomly connected populations of neurons with Hebbian plasticity and inhibition. Assemblies and their operations constitute a computational model of the brain which we call the Assembly Calculus, occupying a level of detail intermediate between the level of spiking neurons and synapses and that of the whole brain. The resulting computational system can be shown, under assumptions, to be, in principle, capable of carrying out arbitrary computations. We hypothesize that something like it may underlie higher human cognitive functions such as reasoning, planning, and language. In particular, we propose a plausible brain architecture based on assemblies for implementing the syntactic processing of language in cortex, which is consistent with recent experimental results.},
  eprint = {32518114},
  eprinttype = {pmid},
  file = {/home/oblivion/Zotero/storage/FJB3LF8F/Papadimitriou et al. - 2020 - Brain computation by assemblies of neurons.pdf;/home/oblivion/Zotero/storage/NENU5QZK/14464.html},
  keywords = {Assembly Calculus,computation,language in the brain,neuronal assemblies,random graph},
  langid = {english},
  number = {25}
}

@inproceedings{papadimitriouCalculusBrainComputation2019,
  title = {A {{Calculus}} for {{Brain Computation}}},
  booktitle = {2019 {{Conference}} on {{Cognitive Computational Neuroscience}}},
  author = {Papadimitriou, Christos H. and Vempala, Santosh S. and Mitropolsky, Daniel and Collins, Michael J. and Maass, Wolfgang and Abbott, Larry F.},
  year = 2019,
  publisher = {{Cognitive Computational Neuroscience}},
  location = {{Berlin, Germany}},
  doi = {10.32470/CCN.2019.1381-0},
  abstract = {Do brains compute? How do brains learn? How are intelligence and language achieved in the human brain? In this pursuit, we develop a formal calculus and associated programming language for brain computation, based on the assembly hypothesis, first proposed by Hebb: the basic unit of memory and computation in the brain is an assembly, a sparse distribution over neurons. We show that assemblies can be realized efficiently and neuroplausibly by using random projection, inhibition, and plasticity. Repeated applications of this RP\&C primitive (random projection and cap) lead to (1) stable assembly creation through projection; (2) association and pattern completion; and finally (3) merge, where two assemblies form a higher-level assembly and, eventually, hierarchies. Further, these operations are composable, allowing the creation of stable computational circuits and structures. We argue that this functionality, in the presence of merge in particular, might underlie language and syntax in humans.},
  eventtitle = {2019 {{Conference}} on {{Cognitive Computational Neuroscience}}},
  file = {/home/oblivion/Zotero/storage/L5HFK4TK/Papadimitriou et al. - 2019 - A Calculus for Brain Computation.pdf},
  langid = {english}
}

@online{pastellWeaveJlScientific2017,
  title = {Weave.Jl: {{Scientific Reports Using Julia}}},
  shorttitle = {Weave.Jl},
  author = {Pastell, Matti},
  year = 2017,
  doi = {10.21105/joss.00204},
  abstract = {Pastell, (2017), Weave.jl: Scientific Reports Using Julia, Journal of Open Source Software, 2(11), 204, doi:10.21105/joss.00204},
  file = {/home/oblivion/Zotero/storage/BWSJPPY5/Pastell - 2017 - Weave.jl Scientific Reports Using Julia.pdf;/home/oblivion/Zotero/storage/SVPHPK4L/joss.html},
  langid = {english},
  organization = {{The Journal of Open Source Software}}
}

@book{patonComputationCellsTissues2013,
  title = {Computation in {{Cells}} and {{Tissues}}: {{Perspectives}} and {{Tools}} of {{Thought}}},
  shorttitle = {Computation in {{Cells}} and {{Tissues}}},
  author = {Paton, R. and Bolouri, Hamid and Holcombe, W. Michael L. and Parish, J. Howard and Tateson, Richard},
  year = 2013,
  publisher = {{Springer Science \& Business Media}},
  abstract = {The field of biologically inspired computation has coexisted with mainstream computing since the 1930s, and the pioneers in this area include Warren McCulloch, Walter Pitts, Robert Rosen, Otto Schmitt, Alan Turing, John von Neumann and Norbert Wiener. Ideas arising out of studies of biology have permeated algorithmics, automata theory, artificial intelligence, graphics, information systems and software design. Within this context, the biomolecular, cellular and tissue levels of biological organisation have had a considerable inspirational impact on the development of computational ideas. Such innovations include neural computing, systolic arrays, genetic and immune algorithms, cellular automata, artificial tissues, DNA computing and protein memories. With the rapid growth in biological knowledge there remains a vast source of ideas yet to be tapped. This includes developments associated with biomolecular, genomic, enzymic, metabolic, signalling and developmental systems and the various impacts on distributed, adaptive, hybrid and emergent computation. This multidisciplinary book brings together a collection of chapters by biologists, computer scientists, engineers and mathematicians who were drawn together to examine the ways in which the interdisciplinary displacement of concepts and ideas could develop new insights into emerging computing paradigms. Funded by the UK Engineering and Physical Sciences Research Council (EPSRC), the CytoCom Network formally met on five occasions to examine and discuss common issues in biology and computing that could be exploited to develop emerging models of computation.},
  eprint = {h8eqCAAAQBAJ},
  eprinttype = {googlebooks},
  isbn = {978-3-662-06369-9},
  keywords = {Computers / Computer Science,Computers / Computer Simulation,Computers / Information Technology,Computers / Intelligence (AI) & Semantics,Computers / Machine Theory,Computers / User Interfaces,Mathematics / Applied,Science / Life Sciences / General},
  langid = {english},
  pagetotal = {349}
}

@book{piagetjeanOriginsIntelligenceChildren,
  title = {The Origins of Intelligence in Children},
  author = {Piaget, Jean},
  file = {/home/oblivion/Zotero/storage/ILMP6T4B/Piaget, Jean - The origins of intelligence in children.pdf},
  keywords = {*}
}

@online{piagetjeanPsychologyIntelligence,
  title = {The {{Psychology}} of {{Intelligence}}},
  author = {Piaget, Jean},
  url = {https://www.goodreads.com/work/best_book/13123281-the-psychology-of-intelligence},
  urldate = {2019-05-28},
  abstract = {Think of developmental psychology, and the name of Jean Piaget immediately springs to mind. His theory of learning lies at the very heart...},
  file = {/home/oblivion/Downloads/9780203981528_googlepreview.pdf;/home/oblivion/Zotero/storage/5DPRYZ6X/Piaget J - Psychology of Intelligence.pdf;/home/oblivion/Zotero/storage/CC88ZBUW/137917.html}
}

@book{piagetOriginsIntelligenceChildren1952,
  title = {The Origins of Intelligence in Children},
  author = {Piaget, Jean},
  year = 1952,
  publisher = {{W W Norton \& Co}},
  location = {{New York, NY, US}},
  doi = {10.1037/11494-000},
  abstract = {This work, a second edition of which has very kindly been requested, was followed by La Construction du réel chez l'enfant and was to have been completed by a study of the genesis of imitation in the child. The latter piece of research, whose publication we have postponed because it is so closely connected with the analysis of play and representational symbolism, appeared in 1945, inserted in a third work, La formation du symbole chez l'enfant. Together these three works form one entity dedicated to the beginnings of intelligence, that is to say, to the various manifestations of sensorimotor intelligence and to the most elementary forms of expression. The theses developed in this volume, which concern in particular the formation of the sensorimotor schemata and the mechanism of mental assimilation, have given rise to much discussion which pleases us and prompts us to thank both our opponents and our sympathizers for their kind interest in our work. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  editorb = {Cook, Margaret},
  editorbtype = {redactor},
  file = {/home/oblivion/Zotero/storage/6W2VMCLB/Piaget - 1952 - The origins of intelligence in children.pdf;/home/oblivion/Zotero/storage/SUGZDH5Z/2007-10742-000.html},
  keywords = {Assimilation (Cognitive Process),Childhood Play Development,Cognitive Development,Imitation (Learning),Intelligence,Nonverbal Communication,Perceptual Motor Development,Symbolism},
  pagetotal = {419},
  series = {The Origins of Intelligence in Children}
}

@book{poghosyanWTSFTimeSeries2020,
  title = {W-{{TSF}}: {{Time Series Forecasting}} with {{Deep Learning}} for {{Cloud Applications}}},
  shorttitle = {W-{{TSF}}},
  author = {Poghosyan, Arnak and Harutyunyan, Ashot and Grigoryan, Naira and Pang, Clement and Oganesyan, George and Sirak, Ghazaryan and Hovhannisyan, Narek},
  year = 2020,
  abstract = {One of the main targets of application performance managers is monitoring of cloud environments with high-velocity custom metrics and analytics. The key components of time series data analytics are forecasting and anomaly detection. The classical methods of time series forecasting were recently empowered by neural network-based models which gain increasing popularity due to their flexibility and ability to tackle complex non-linear problems. Meanwhile, some of the disadvantages of that approach mitigate expectations and require specific solution for SaaS applications. The first challenge for network-based models is resource utilization due to GPU trainings. SaaS applications are extremely sensitive to luxury resources due to high costs. The second challenge is inability of the networks to handle non-stationary time series data that behave with trend and/or seasonality. In this paper, we propose W-TSF, a time series forecasting engine that was preliminary designed for Wavefront by VMware, a monitoring tool for cloud environments. W-TSF resolves all mentioned problems. Implementation and testing for real-customer time series data proved its acceptable capabilities for cloud environments in terms of prediction accuracy and resource consumption.}
}

@article{praveenaAnomalyDetectionInfrastructure2016,
  title = {Anomaly {{Detection}} in {{Infrastructure Service}} of {{Cloud Computing}}},
  author = {Praveena, N},
  year = 2016,
  volume = {4},
  pages = {5},
  abstract = {Cloud services are prominent within the private, public and commercial domains. Many of these services are expected to be always on and have a critical nature; therefore, security and resilience are increasingly important aspects. In order to remain resilient, a cloud needs to possess the ability to react not only to known threats, but also to new challenges that target cloud infrastructures. In this paper we introduce and discuss an online cloud anomaly detection approach, comprising dedicated detection components of our cloud resilience architecture. More specifically, we exhibit the applicability of novelty detection under the one-class support Vector Machine (SVM) formulation at the hypervisor level, through the utilisation of features gathered at the system and network levels of a cloud node. We demonstrate that our scheme can reach a high detection accuracy of over 90\% whilst detecting various types of malware and DoS attacks. Furthermore, we evaluate the merits of considering not only system-level data, but also network-level data depending on the attack type. Finally, the paper shows that our approach to detection using dedicated monitoring components per VM is particularly applicable to cloud scenarios and leads to a flexible detection system capable of detecting new malware strains with no prior knowledge of their functionality or their underlying instructions.},
  file = {/home/oblivion/Zotero/storage/XBMPJTE6/Praveena - 2016 - Anomaly Detection in Infrastructure Service of Clo.pdf},
  langid = {english},
  number = {6}
}

@online{PrinciplesNeuralScience,
  title = {Principles of {{Neural Science}}, {{Fifth Edition}} | {{AccessNeurology}} | {{McGraw}}-{{Hill Medical}}},
  url = {https://neurology.mhmedical.com/book.aspx?bookID=1049},
  urldate = {2019-06-02},
  file = {/home/oblivion/Zotero/storage/MXATRSZN/book.html}
}

@article{pritchardMicroRNAProfilingApproaches2012,
  title = {{{MicroRNA}} Profiling: Approaches and Considerations},
  shorttitle = {{{MicroRNA}} Profiling},
  author = {Pritchard, Colin C. and Cheng, Heather H. and Tewari, Muneesh},
  year = 2012,
  journaltitle = {Nature reviews. Genetics},
  shortjournal = {Nat Rev Genet},
  volume = {13},
  pages = {358--369},
  issn = {1471-0056},
  doi = {10.1038/nrg3198},
  abstract = {MicroRNAs (miRNAs) are small RNAs (\textasciitilde 22 nt long) that post-transcriptionally regulate the expression of thousands of genes in a broad range of organisms, in both normal physiologic and disease contexts. MiRNA expression profiling is gaining popularity because miRNAs, as key regulators in gene expression networks, can influence many biological processes and have also shown promise as biomarkers for disease. Technological advances have enabled the development of various platforms for miRNA profiling, and an understanding of the strengths and pitfalls of different approaches can aid in the effective use of miRNA profiling for diverse applications. We review here the major considerations for carrying out and interpreting results of miRNA profiling studies, as well as current and emerging applications of miRNA profiling.},
  eprint = {22510765},
  eprinttype = {pmid},
  file = {/home/oblivion/Zotero/storage/VFMATCTE/Pritchard et al. - 2012 - MicroRNA profiling approaches and considerations.pdf},
  number = {5},
  pmcid = {PMC4517822}
}

@online{pronschinske47AdvancedTutorials,
  title = {47 Advanced Tutorials for Mastering {{Kubernetes}}},
  author = {Pronschinske, Mitch},
  url = {https://techbeacon.com/enterprise-it/47-advanced-tutorials-mastering-kubernetes},
  urldate = {2019-08-28},
  abstract = {If you're serious about learning Kubernetes, or want to grow your knowledge about the platform in a specific area, look here first.},
  file = {/home/oblivion/Zotero/storage/FAD8YW3F/47-advanced-tutorials-mastering-kubernetes.html},
  langid = {english},
  organization = {{TechBeacon}}
}

@online{purdyEncodingDataHTM2016,
  title = {Encoding {{Data}} for {{HTM Systems}}},
  author = {Purdy, Scott},
  year = 2016,
  url = {http://arxiv.org/abs/1602.05925},
  urldate = {2019-06-02},
  abstract = {Hierarchical Temporal Memory (HTM) is a biologically inspired machine intelligence technology that mimics the architecture and processes of the neocortex. In this white paper we describe how to encode data as Sparse Distributed Representations (SDRs) for use in HTM systems. We explain several existing encoders, which are available through the open source project called NuPIC, and we discuss requirements for creating encoders for new types of data.},
  archiveprefix = {arXiv},
  eprint = {1602.05925},
  eprinttype = {arxiv},
  file = {/home/oblivion/Zotero/storage/CWZIU39V/Purdy - 2016 - Encoding Data for HTM Systems.pdf;/home/oblivion/Zotero/storage/FLNJ4DYG/1602.html},
  keywords = {Computer Science - Neural and Evolutionary Computing,Quantitative Biology - Neurons and Cognition},
  primaryclass = {cs, q-bio}
}

@misc{q-successdigelbmanngmbhWordPressVsDrupal,
  title = {{{WordPress}} vs. {{Drupal}} Usage Statistics, {{February}} 2021},
  howpublished = "\url{https://w3techs.com/technologies/comparison/cm-drupal,cm-wordpress}",
  note = "Accessed: 2021-02-21",
  year = 2021
}

@misc{openPolicyAgent,
  title = "Open Policy Agent",
  howpublished = "\url{https://www.openpolicyagent.org/}",
  note = "Accessed: 2021-06-03",
  year = 2021
}

@misc{helmsh,
  title = "Helm",
  howpublished = "\url{https://helm.sh/}",
  note = "Accessed: 2021-06-03",
  year = 2021
}

@misc{argocd,
  title = "Argo CD -- Declarative GitOps CD for Kubernetes",
  howpublished = "\url{https://argo-cd.readthedocs.io/en/stable/}",
  note = "Accessed: 2021-06-03",
  year = 2021
}

@misc{hpascaling,
  title = "Horizontal Pod Autoscaler",
  howpublished = "\url{https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/}",
  note = "Accessed: 2021-06-03",
  year = 2021
}

@misc{locustio,
  title = "Locust",
  howpublished = "\url{https://locust.io/}",
  note = "Accessed: 2021-06-03",
  year = 2021
}

@misc{kubeconCernOperators,
  title = "CERN's 1500 Drupal Websites on Kubernetes: Sailing With Operators",
  howpublished = "\url{https://sched.co/iE362}",
  note = "Accessed: 2021-06-03",
  year = 2021
}

@misc{cncfLandscape,
  title = "CNCF Landscape",
  howpublished = "\url{https://landscape.cncf.io/}",
  note = "Accessed: 2021-06-03",
  year = 2021
}

@software{qntmFSMRegexConversion2019,
  title = {{{FSM}}/Regex Conversion Library. {{Contribute}} to Qntm/Greenery Development by Creating an Account on {{GitHub}}},
  author = {{qntm}},
  date = {2019-07-08T14:06:20Z},
  origdate = {2012-07-22T17:10:11Z},
  url = {https://github.com/qntm/greenery},
  urldate = {2019-07-23}
}

@online{QntmGreeneryFSM,
  title = {Qntm/Greenery: {{FSM}}/Regex Conversion Library},
  url = {https://github.com/qntm/greenery},
  urldate = {2019-07-23},
  file = {/home/oblivion/Zotero/storage/4W53TBPW/greenery.html}
}

@article{rashkovNaturalImageReconstruction2019,
  title = {Natural Image Reconstruction from Brain Waves: A Novel Visual {{BCI}} System with Native Feedback},
  shorttitle = {Natural Image Reconstruction from Brain Waves},
  author = {Rashkov, Grigory and Bobe, Anatoly and Fastovets, Dmitry and Komarova, Maria},
  year = 2019,
  journaltitle = {bioRxiv},
  pages = {787101},
  doi = {10.1101/787101},
  abstract = {{$<$}p{$>$}Here we hypothesize that observing the visual stimuli of different categories trigger distinct brain states that can be decoded from noninvasive EEG recordings. We introduce an effective closed-loop BCI system that reconstructs the observed or imagined stimuli images from the co-occurring brain wave parameters. The reconstructed images are presented to the subject as a visual feedback. The developed system is applicable to training BCI-naive subjects because of the user-friendly and intuitive way the visual patterns are employed to modify the brain states.{$<$}/p{$>$}},
  file = {/home/oblivion/Zotero/storage/HHLUK98Q/Rashkov et al. - 2019 - Natural image reconstruction from brain waves a n.pdf;/home/oblivion/Zotero/storage/SA8G23JR/787101v3.html},
  langid = {english}
}

@online{regierLearningAstronomicalCatalog2016,
  title = {Learning an {{Astronomical Catalog}} of the {{Visible Universe}} through {{Scalable Bayesian Inference}}},
  author = {Regier, Jeffrey and Pamnany, Kiran and Giordano, Ryan and Thomas, Rollin and Schlegel, David and McAuliffe, Jon and Prabhat},
  year = 2016,
  url = {http://arxiv.org/abs/1611.03404},
  urldate = {2019-05-29},
  abstract = {Celeste is a procedure for inferring astronomical catalogs that attains state-of-the-art scientific results. To date, Celeste has been scaled to at most hundreds of megabytes of astronomical images: Bayesian posterior inference is notoriously demanding computationally. In this paper, we report on a scalable, parallel version of Celeste, suitable for learning catalogs from modern large-scale astronomical datasets. Our algorithmic innovations include a fast numerical optimization routine for Bayesian posterior inference and a statistically efficient scheme for decomposing astronomical optimization problems into subproblems. Our scalable implementation is written entirely in Julia, a new high-level dynamic programming language designed for scientific and numerical computing. We use Julia's high-level constructs for shared and distributed memory parallelism, and demonstrate effective load balancing and efficient scaling on up to 8192 Xeon cores on the NERSC Cori supercomputer.},
  archiveprefix = {arXiv},
  eprint = {1611.03404},
  eprinttype = {arxiv},
  file = {/home/oblivion/Zotero/storage/48PXE38L/Regier et al. - 2016 - Learning an Astronomical Catalog of the Visible Un.pdf;/home/oblivion/Zotero/storage/E99Q6Y2N/1611.html},
  keywords = {85A35 (Primary); 68W10; 62P35,Astrophysics - Instrumentation and Methods for Astrophysics,Computer Science - Distributed; Parallel; and Cluster Computing,Computer Science - Machine Learning,D.1.3,D.2,G.3,I.2,J.2,Statistics - Applications,Statistics - Machine Learning},
  primaryclass = {astro-ph, stat}
}

@article{richardsDeepLearningFramework2019,
  title = {A Deep Learning Framework for Neuroscience},
  author = {Richards, Blake A. and Lillicrap, Timothy P. and Beaudoin, Philippe and Bengio, Yoshua and Bogacz, Rafal and Christensen, Amelia and Clopath, Claudia and Costa, Rui Ponte and family=Berker, given=Archy, prefix=de, useprefix=false and Ganguli, Surya and Gillon, Colleen J. and Hafner, Danijar and Kepecs, Adam and Kriegeskorte, Nikolaus and Latham, Peter and Lindsay, Grace W. and Miller, Kenneth D. and Naud, Richard and Pack, Christopher C. and Poirazi, Panayiota and Roelfsema, Pieter and Sacramento, João and Saxe, Andrew and Scellier, Benjamin and Schapiro, Anna C. and Senn, Walter and Wayne, Greg and Yamins, Daniel and Zenke, Friedemann and Zylberberg, Joel and Therien, Denis and Kording, Konrad P.},
  year = 2019,
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {22},
  pages = {1761--1770},
  issn = {1546-1726},
  doi = {10.1038/s41593-019-0520-2},
  abstract = {A deep network is best understood in terms of components used to design it—objective functions, architecture and learning rules—rather than unit-by-unit computation. Richards et al. argue that this inspires fruitful approaches to systems neuroscience.},
  file = {/home/oblivion/Zotero/storage/SFW7TXSU/Richards et al. - 2019 - A deep learning framework for neuroscience.pdf;/home/oblivion/Zotero/storage/IG56RI8L/s41593-019-0520-2.html},
  langid = {english},
  number = {11}
}

@article{rossumStableHebbianLearning2000,
  title = {Stable {{Hebbian Learning}} from {{Spike Timing}}-{{Dependent Plasticity}}},
  author = {family=Rossum, given=M. C. W., prefix=van, useprefix=false and Bi, G. Q. and Turrigiano, G. G.},
  year = 2000,
  journaltitle = {Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {20},
  pages = {8812--8821},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.20-23-08812.2000},
  abstract = {We explore a synaptic plasticity model that incorporates recent findings that potentiation and depression can be induced by precisely timed pairs of synaptic events and postsynaptic spikes. In addition we include the observation that strong synapses undergo relatively less potentiation than weak synapses, whereas depression is independent of synaptic strength. After random stimulation, the synaptic weights reach an equilibrium distribution which is stable, unimodal, and has positive skew. This weight distribution compares favorably to the distributions of quantal amplitudes and of receptor number observed experimentally in central neurons and contrasts to the distribution found in plasticity models without size-dependent potentiation. Also in contrast to those models, which show strong competition between the synapses, stable plasticity is achieved with little competition. Instead, competition can be introduced by including a separate mechanism that scales synaptic strengths multiplicatively as a function of postsynaptic activity. In this model, synaptic weights change in proportion to how correlated they are with other inputs onto the same postsynaptic neuron. These results indicate that stable correlation-based plasticity can be achieved without introducing competition, suggesting that plasticity and competition need not coexist in all circuits or at all developmental stages.},
  eprint = {11102489},
  eprinttype = {pmid},
  file = {/home/oblivion/Zotero/storage/S8BVA3I8/Rossum et al. - 2000 - Stable Hebbian Learning from Spike Timing-Dependen.pdf;/home/oblivion/Zotero/storage/ZZWCEEAX/8812.html},
  keywords = {activity-dependent scaling,Hebbian plasticity,stochastic approaches,synaptic competition,synaptic weights,temporal learning},
  langid = {english},
  number = {23}
}

@article{rothEvolutionBrainIntelligence2005,
  title = {Evolution of the Brain and Intelligence},
  author = {Roth, Gerhard and Dicke, Ursula},
  year = 2005,
  journaltitle = {Trends in Cognitive Sciences},
  shortjournal = {Trends in Cognitive Sciences},
  volume = {9},
  pages = {250--257},
  issn = {1364-6613},
  doi = {10.1016/j.tics.2005.03.005},
  abstract = {Intelligence has evolved many times independently among vertebrates. Primates, elephants and cetaceans are assumed to be more intelligent than ‘lower’ mammals, the great apes and humans more than monkeys, and humans more than the great apes. Brain properties assumed to be relevant for intelligence are the (absolute or relative) size of the brain, cortex, prefrontal cortex and degree of encephalization. However, factors that correlate better with intelligence are the number of cortical neurons and conduction velocity, as the basis for information-processing capacity. Humans have more cortical neurons than other mammals, although only marginally more than whales and elephants. The outstanding intelligence of humans appears to result from a combination and enhancement of properties found in non-human primates, such as theory of mind, imitation and language, rather than from ‘unique’ properties.},
  file = {/home/oblivion/Zotero/storage/6L4PIDRF/S1364661305000823.html},
  number = {5}
}

@online{RunningDrupalKubernetes,
  title = {Running {{Drupal}} in {{Kubernetes}} with {{Docker}} in Production | {{Jeff Geerling}}},
  url = {https://www.jeffgeerling.com/blog/2019/running-drupal-kubernetes-docker-production},
  urldate = {2019-08-28},
  file = {/home/oblivion/Zotero/storage/R4DDCN6W/running-drupal-kubernetes-docker-production.html}
}

@incollection{sabourDynamicRoutingCapsules2017,
  title = {Dynamic {{Routing Between Capsules}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 30},
  author = {Sabour, Sara and Frosst, Nicholas and Hinton, Geoffrey E},
  editor = {Guyon, I. and Luxburg, U. V. and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
  year = 2017,
  pages = {3856--3866},
  publisher = {{Curran Associates, Inc.}},
  url = {http://papers.nips.cc/paper/6975-dynamic-routing-between-capsules.pdf},
  urldate = {2019-05-30},
  file = {/home/oblivion/Zotero/storage/8ALFIDQS/Sabour et al. - 2017 - Dynamic Routing Between Capsules.pdf;/home/oblivion/Zotero/storage/789HH3KQ/6975-dynamic-routing-between-capsules.html}
}

@inproceedings{sabourMatrixCapsulesEM2018,
  title = {Matrix Capsules with {{EM}} Routing},
  author = {Sabour, Sara and Frosst, Nicholas and Hinton, G},
  year = 2018,
  eventtitle = {6th {{International Conference}} on {{Learning Representations}}, {{ICLR}}}
}

@article{sauvanaudAnomalyDetectionDiagnosis2018,
  title = {Anomaly Detection and Diagnosis for Cloud Services: {{Practical}} Experiments and Lessons Learned},
  shorttitle = {Anomaly Detection and Diagnosis for Cloud Services},
  author = {Sauvanaud, Carla and Kaâniche, Mohamed and Kanoun, Karama and Lazri, Kahina and Da Silva Silvestre, Guthemberg},
  year = 2018,
  journaltitle = {Journal of Systems and Software},
  shortjournal = {Journal of Systems and Software},
  volume = {139},
  pages = {84--106},
  issn = {0164-1212},
  doi = {10.1016/j.jss.2018.01.039},
  abstract = {The dependability of cloud computing services is a major concern of cloud providers. In particular, anomaly detection techniques are crucial to detect anomalous service behaviors that may lead to the violation of service level agreements (SLAs) drawn with users. This paper describes an anomaly detection system (ADS) designed to detect errors related to the erroneous behavior of the service, and SLA violations in cloud services. One major objective is to help providers to diagnose the anomalous virtual machines (VMs) on which a service is deployed as well as the type of error associated to the anomaly. Our ADS includes a system monitoring entity that collects software counters characterizing the cloud service, as well as a detection entity based on machine learning models. Additionally, a fault injection entity is integrated into the ADS for the training the machine learning models. This entity is also used to validate the ADS and to assess its anomaly detection and diagnosis performance. We validated our ADS with two case studies deployments: a NoSQL database, and a virtual IP Multimedia Subsystem developed implementing a virtual network function. Experimental results show that our ADS can achieve a high detection and diagnosis performance.},
  file = {/home/oblivion/Zotero/storage/7NV926G2/S0164121218300256.html},
  keywords = {Anomaly detection,Diagnosis,Fault injection,Machine learning,SLA,System monitoring,Virtualization},
  langid = {english}
}

@book{sayfanHandsOnMicroservicesKubernetes2019,
  title = {Hands-{{On Microservices}} with {{Kubernetes}}: {{Build}}, Deploy, and Manage Scalable Microservices on {{Kubernetes}}},
  shorttitle = {Hands-{{On Microservices}} with {{Kubernetes}}},
  author = {Sayfan, Gigi},
  year = 2019,
  publisher = {{Packt Publishing Ltd}},
  abstract = {Enhance your skills in building scalable infrastructure for your cloud-based applicationsKey FeaturesLearn to design a scalable architecture by building continuous integration (CI) pipelines with KubernetesGet an in-depth understanding of role-based access control (RBAC), continuous deployment (CD), and observabilityMonitor a Kubernetes cluster with Prometheus and GrafanaBook DescriptionKubernetes is among the most popular open-source platforms for automating the deployment, scaling, and operations of application containers across clusters of hosts, providing a container-centric infrastructure.Hands-On Microservices with Kubernetes starts by providing you with in-depth insights into the synergy between Kubernetes and microservices. You will learn how to use Delinkcious, which will serve as a live lab throughout the book to help you understand microservices and Kubernetes concepts in the context of a real-world application. Next, you will get up to speed with setting up a CI/CD pipeline and configuring microservices using Kubernetes ConfigMaps. As you cover later chapters, you will gain hands-on experience in securing microservices, and implementing REST, gRPC APIs, and a Delinkcious data store. In addition to this, you’ll explore the Nuclio project, run a serverless task on Kubernetes, and manage and implement data-intensive tests. Toward the concluding chapters, you’ll deploy microservices on Kubernetes and learn to maintain a well-monitored system. Finally, you’ll discover the importance of service meshes and how to incorporate Istio into the Delinkcious cluster. By the end of this book, you’ll have gained the skills you need to implement microservices on Kubernetes with the help of effective tools and best practices.What you will learnUnderstand the synergy between Kubernetes and microservicesCreate a complete CI/CD pipeline for your microservices on KubernetesDevelop microservices on Kubernetes with the Go kit framework using best practicesManage and monitor your system using Kubernetes and open-source toolsExpose your services through REST and gRPC APIsImplement and deploy serverless functions as a serviceExternalize authentication, authorization and traffic shaping using a service meshRun a Kubernetes cluster in the cloud on Google Kubernetes EngineWho this book is forThis book is for developers, DevOps engineers, or anyone who wants to develop large-scale microservice-based systems on top of Kubernetes. If you are looking to use Kubernetes on live production projects or want to migrate existing systems to a modern containerized microservices system, then this book is for you. Coding skills, together with some knowledge of Docker, Kubernetes, and cloud concepts will be useful.},
  eprint = {AEahDwAAQBAJ},
  eprinttype = {googlebooks},
  isbn = {978-1-78980-973-2},
  keywords = {Computers / Hardware / Peripherals,Computers / Networking / General,Computers / Security / Networking,Computers / System Administration / Storage & Retrieval,Computers / Systems Architecture / Distributed Systems & Computing},
  langid = {english},
  pagetotal = {494}
}

@article{schlesigerHippocampalGlobalRemapping2018,
  title = {Hippocampal {{Global Remapping Can Occur}} without {{Input}} from the {{Medial Entorhinal Cortex}}},
  author = {Schlesiger, Magdalene I. and Boublil, Brittney L. and Hales, Jena B. and Leutgeb, Jill K. and Leutgeb, Stefan},
  year = 2018,
  journaltitle = {Cell Reports},
  shortjournal = {Cell Reports},
  volume = {22},
  pages = {3152--3159},
  issn = {2211-1247},
  doi = {10.1016/j.celrep.2018.02.082},
  abstract = {{$<$}h2{$>$}Summary{$<$}/h2{$><$}p{$>$}The high storage capacity of the episodic memory system relies on distinct representations for events that are separated in time and space. The spatial component of these computations includes the formation of independent maps by hippocampal place cells across environments, referred to as global remapping. Such remapping is thought to emerge by the switching of input patterns from specialized spatially selective cells in medial entorhinal cortex (mEC), such as grid and border cells. Although it has been shown that acute manipulations of mEC firing patterns are sufficient for inducing hippocampal remapping, it remains unknown whether specialized spatial mEC inputs are necessary for the reorganization of hippocampal spatial representations. Here, we examined remapping in rats without mEC input to the hippocampus and found that highly distinct spatial maps emerged rapidly in every individual rat. Our data suggest that hippocampal spatial computations do not depend on inputs from specialized cell types in mEC.{$<$}/p{$>$}},
  eprint = {29562172},
  eprinttype = {pmid},
  file = {/home/oblivion/Zotero/storage/DSKDJ84Z/Schlesiger et al. - 2018 - Hippocampal Global Remapping Can Occur without Inp.pdf;/home/oblivion/Zotero/storage/KKKKA7SX/S2211-1247(18)30292-4.html},
  langid = {english},
  number = {12}
}

@inproceedings{shahNovelAlgebrasAdvanced2013,
  title = {Novel Algebras for Advanced Analytics in {{Julia}}},
  booktitle = {2013 {{IEEE High Performance Extreme Computing Conference}} ({{HPEC}})},
  author = {Shah, V. B. and Edelman, A. and Karpinski, S. and Bezanson, J. and Kepner, J.},
  year = 2013,
  pages = {1--4},
  doi = {10.1109/HPEC.2013.6670347},
  abstract = {A linear algebraic approach to graph algorithms that exploits the sparse adjacency matrix representation of graphs can provide a variety of benefits. These benefits include syntactic simplicity, easier implementation, and higher performance. One way to employ linear algebra techniques for graph algorithms is to use a broader definition of matrix and vector multiplication. We demonstrate through the use of the Julia language system how easy it is to explore semirings using linear algebraic methodologies.},
  eventtitle = {2013 {{IEEE High Performance Extreme Computing Conference}} ({{HPEC}})},
  file = {/home/oblivion/Zotero/storage/FDYSCV7C/Shah et al. - 2013 - Novel algebras for advanced analytics in Julia.pdf;/home/oblivion/Zotero/storage/VSWD2839/6670347.html},
  keywords = {advanced analytics,Electronic mail,graph algorithms,high level languages,Julia,Julia language system,linear algebra,linear algebra techniques,linear algebraic approach,linear algebraic methodologies,mathematics computing,Matrices,matrix multiplication,novel algebras,sparse adjacency matrix representation,Sparse matrices,Standards,Syntactics,vector multiplication}
}

@article{shawGerminateDevelopmentCommon2017,
  title = {Germinate 3 : Development of a Common Platform to Support the Distribution of Experimental Data on Crop Wild Relatives},
  shorttitle = {Germinate 3},
  author = {Shaw, P. and Raubach, S. and Hearne, S. and Dreher, K. and Bryan, G. and McKenzie, Gaynor and Milne, I. and Stephen, G. and Marshall, D.},
  year = 2017,
  doi = {10.2135/CROPSCI2016.09.0814},
  abstract = {Conservation and exploitation of crop wild relative species is an important component in ensuring food security and improving current agricultural output. By identifying agriculturally important characteristics that express favorable response to both biotic and abiotic stress currently unused by breeders, the incorporation of this new genetic material into genetic background stocks may help mitigate problems imposed by climate change, land degradation, and population pressure. This is particularly important in countries that will be more severely affected by the threat of reduced yields. The ability to effectively manage genetic resources collections and integrate unique and diverse data types is crucial in exploring, understanding, and exploiting the diversity contained within genebanks. Providing a common interface through which experimental and background data can be disseminated to both researchers and breeders will bring focus and facilitate community building into research communities. We have taken wild barley (Hordeum spp.) and potato (Solanum spp.) collections along with wheat (Triticum spp.) and maize (Zea mays subsp. mays) and their wild relatives and incorporated this data into web-based information resources built using the Germinate platform (https://ics. hutton.ac.uk/get-germinate, accessed 4 Apr. 2017). We have tailored these to better meet the demands of researchers by developing both new data visualization tools and integration with current software such as Helium, Flapjack, and CurlyWhirly (https://ics.hutton.ac.uk/software, accessed 4 Apr. 2017) and presented the data in a common platform. While the underlying species differ, the approach taken ensures that tools are compatible across all database instances. We will describe these database instances and show that Germinate offers a common platform that will aid in the exploration and wider use of these species. P.D. Shaw, S. Raubach, I. Milne, G. Stephen, and D.F. Marshall, Information and Computational Sciences, The James Hutton Institute, Errol Road, Invergowrie, Dundee, DD2 5DA, Scotland; G. Bryan and G. McKenzie, Cell and Molecular Sciences, James Hutton Institute, Errol Road, Invergowrie, Dundee, DD2 5DA, Scotland; K. Dreher and S. Hearne, International Maize and Wheat Improvement Center (CIMMYT), Texcoco, Edo. De Mexico, Mexico CP 56237. Received 28 Sept. 2016. Accepted 13 Mar. 2017. *Corresponding author (paul. shaw@hutton.ac.uk). Assigned to Associate Editor Hem Bhandari. Abbreviations: CIMMYT, Centro Internacional de Mejoramiento de Maíz y Trigo; CPC, Commonwealth Potato Collection; CWR, crop wild relative; DOI, data object identifier; GWAS, genome-wide association scan; GWT, GWT Web Toolkit; ITPGRFA, International Treaty on Plant Genetic Resources for Food and Agriculture; MCPD, MultiCrop Passport Descriptors; PCA, principal component analysis; PCO, principal coordinate analysis; SeeD, Seeds of Discovery; SNP, single nucleotide polymorphism. Published in Crop Sci. 57:1259–1273 (2017). doi: 10.2135/cropsci2016.09.0814 © Crop Science Society of America | 5585 Guilford Rd., Madison, WI 53711 USA This is an open access article distributed under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/). Published June 16, 2017},
  file = {/home/oblivion/Zotero/storage/9NUWAX7Q/Shaw et al. - 2017 - Germinate 3  development of a common platform to .pdf}
}

@inproceedings{shcherbakovSurveyForecastError2013,
  title = {A {{Survey}} of {{Forecast Error Measures}}},
  author = {Shcherbakov, Maxim and Brebels, Adriaan and Tyukov, Anton and Janovsky, Timur and Anatol, Valeriy},
  year = 2013,
  abstract = {Submitted: Aug 7, 2013; Accepted: Sep 18, 2013; Published: Sep 25, 2013 Abstract: This article reviews the common used forecast error measurements. All error measurements have been joined in the seven groups: absolute forecasting errors, measures based on percentage errors, symmetric errors, measures based on relative errors, scaled errors, relative measures and other error measures. The formulas are presented and drawbacks are discussed for every accuracy measurements. To reduce the impact of outliers, an Integral Normalized Mean Square Error have been proposed. Due to the fact that each error measure has the disadvantages that can lead to inaccurate evaluation of the forecasting results, it is impossible to choose only one measure, the recommendations for selecting the appropriate error measurements are given.},
  file = {/home/oblivion/Zotero/storage/YQG6NJ4S/Shcherbakov et al. - 2013 - A Survey of Forecast Error Measures.pdf},
  keywords = {Mean squared error,Projections and Predictions}
}

@article{shiAnomalyDetectionKey2018,
  title = {Anomaly {{Detection}} for {{Key Performance Indicators Through Machine Learning}}},
  author = {Shi, Jia and He, G. and Liu, Xinwen},
  year = 2018,
  journaltitle = {2018 International Conference on Network Infrastructure and Digital Content (IC-NIDC)},
  doi = {10.1109/ICNIDC.2018.8525714},
  abstract = {The data center and servers generates a large amount of monitoring data and logs every day. With the rapid development of the Internet, web services have penetrated into all areas of society. The stability of the Web services depends on IT operations to guarantee, operations staff through the monitoring of various key performance indicators (KPIs) to judge whether the Web service is stable or not. We want to use the statistical and machine learning methods to detect anomalous. In this paper, we split the problem into two parts. In the first place, we use time series analysis method such as Triple Order Exponential Smoothing (Holt-Winters) and ARIMA model and regression-based machine learning techniques such as Gradient Boosting Regression Trees (GBRT) and Long Short-Term Memory (LSTM) to predict the value at the next point in the time series. After that, we set the anomaly detection rule. Finally we compare the predicted value with actual value to determine whether the current point is anomalous or not.}
}

@inproceedings{shteimanWhyCMSPlatforms2014,
  title = {Why {{CMS}} Platforms Are Breeding Security Vulnerabilities},
  booktitle = {Network {{Security}}},
  author = {Shteiman, Barry},
  year = 2014,
  volume = {2014},
  pages = {7--9},
  doi = {10.1016/S1353-4858(14)70006-6},
  abstract = {Several statistics-gathering engines on the web reveal an interesting picture. Content management systems (CMS) have become far more popular in the past couple of years. A trend graph over at builtwith.com shows that over 20\% of the top 10,000 websites rely on CMS.1 And it's fair to assume that the number is higher for companies that use a CMS as a middleware between their content and their front-end website. But like all software, and this is without exception, CMSs have many security concerns. Content management systems (CMS) have become far more popular in the past couple of years. But like all software, CMSs have many security concerns. Third-party software like this is out of your control. The popularity of CMSs has been a boon for hackers, giving them a much larger surface area to attack. But, as Barry Shteiman of Imperva explains, there are steps you can take to improve your security when using CMSs.},
  langid = {english}
}

@article{shteimanWhyCMSPlatforms2014a,
  title = {Why {{CMS}} Platforms Are Breeding Security Vulnerabilities},
  author = {Shteiman, Barry},
  year = 2014,
  journaltitle = {Network Security},
  shortjournal = {Network Security},
  volume = {2014},
  pages = {7--9},
  issn = {1353-4858},
  doi = {10.1016/S1353-4858(14)70006-6},
  abstract = {Several statistics-gathering engines on the web reveal an interesting picture. Content management systems (CMS) have become far more popular in the past couple of years. A trend graph over at builtwith.com shows that over 20\% of the top 10,000 websites rely on CMS.1 And it's fair to assume that the number is higher for companies that use a CMS as a middleware between their content and their front-end website. But like all software, and this is without exception, CMSs have many security concerns. Content management systems (CMS) have become far more popular in the past couple of years. But like all software, CMSs have many security concerns. Third-party software like this is out of your control. The popularity of CMSs has been a boon for hackers, giving them a much larger surface area to attack. But, as Barry Shteiman of Imperva explains, there are steps you can take to improve your security when using CMSs.},
  file = {/home/oblivion/Zotero/storage/TMGBVTIJ/S1353485814700066.html},
  langid = {english},
  number = {1}
}

@inproceedings{simkoREANASystemReusable2019,
  title = {{{REANA}}: {{A System}} for {{Reusable Research Data Analyses}}},
  shorttitle = {{{REANA}}},
  author = {Simko, T. and Heinrich, L. and Hirvonsalo, Harri and Kousidis, Dinos and Rodriguez, D.},
  year = 2019,
  doi = {10.1051/EPJCONF/201921406034},
  abstract = {The revalidation, reinterpretation and reuse of research data analyses requires having access to the original computing environment, the experimental datasets, the analysis software, and the computational workflow steps which were used by researchers to produce the original scientific results in the first place.REANA (Reusable Analyses) is a nascent platform enabling researchers to structure their research data analyses in view of enabling future reuse. The analysis is described by means of a YAML file that captures sufficient information about the analysis assets, parameters and processes. The REANA platform consists of a set of micro-services allowing to launch and monitor container-based computational workflow jobs on the cloud. The REANA user interface and the command-line client enables researchers to easily rerun analysis workflows with new input parameters. The REANA platform aims at supporting several container technologies (Docker), workflow engines (CWL, Yadage), shared storage systems (Ceph, EOS) and compute cloud infrastructures (Ku-bernetes/OpenStack, HTCondor) used by the community.REANA was developed with the particle physics use case in mind and profits from synergies with general reusable research data analysis patterns in other scientific disciplines, such as bioinformatics and life sciences.},
  file = {/home/oblivion/Zotero/storage/2PAH3CQT/Simko et al. - 2019 - REANA A System for Reusable Research Data Analyse.pdf}
}

@article{simkoREANASystemReusable2019a,
  title = {{{REANA}}: {{A System}} for {{Reusable Research Data Analyses}}},
  shorttitle = {{{REANA}}},
  author = {Šimko, Tibor and Heinrich, Lukas and Hirvonsalo, Harri and Kousidis, Dinos and Rodríguez, Diego},
  year = 2019,
  journaltitle = {EPJ Web of Conferences},
  shortjournal = {EPJ Web Conf.},
  volume = {214},
  pages = {06034},
  publisher = {{EDP Sciences}},
  issn = {2100-014X},
  doi = {10.1051/epjconf/201921406034},
  abstract = {The revalidation, reinterpretation and reuse of research data analyses requires having access to the original computing environment, the experimental datasets, the analysis software, and the computational workflow steps which were used by researchers to produce the original scientific results in the first place.REANA (Reusable Analyses) is a nascent platform enabling researchers to structure their research data analyses in view of enabling future reuse. The analysis is described by means of a YAML file that captures sufficient information about the analysis assets, parameters and processes. The REANA platform consists of a set of micro-services allowing to launch and monitor container-based computational workflow jobs on the cloud. The REANA user interface and the command-line client enables researchers to easily rerun analysis workflows with new input parameters. The REANA platform aims at supporting several container technologies (Docker), workflow engines (CWL, Yadage), shared storage systems (Ceph, EOS) and compute cloud infrastructures (Ku-bernetes/OpenStack, HTCondor) used by the community.REANA was developed with the particle physics use case in mind and profits from synergies with general reusable research data analysis patterns in other scientific disciplines, such as bioinformatics and life sciences.},
  file = {/home/oblivion/Zotero/storage/2FM7I3KU/Šimko et al. - 2019 - REANA A System for Reusable Research Data Analyse.pdf;/home/oblivion/Zotero/storage/7Z3EMKWL/epjconf_chep2018_06034.html},
  langid = {english}
}

@article{songCompetitiveHebbianLearning2000,
  title = {Competitive {{Hebbian}} Learning through Spike-Timing-Dependent Synaptic Plasticity},
  author = {Song, Sen and Miller, Kenneth D. and Abbott, L. F.},
  year = 2000,
  journaltitle = {Nature Neuroscience},
  volume = {3},
  pages = {919},
  issn = {1546-1726},
  doi = {10.1038/78829},
  abstract = {Hebbian models of development and learning require both activity-dependent synaptic plasticity and a mechanism that induces competition between different synapses. One form of experimentally observed long-term synaptic plasticity, which we call spike-timing-dependent plasticity (STDP), depends on the relative timing of pre- and postsynaptic action potentials. In modeling studies, we find that this form of synaptic modification can automatically balance synaptic strengths to make postsynaptic firing irregular but more sensitive to presynaptic spike timing. It has been argued that neurons in vivo operate in such a balanced regime. Synapses modifiable by STDP compete for control of the timing of postsynaptic action potentials. Inputs that fire the postsynaptic neuron with short latency or that act in correlated groups are able to compete most successfully and develop strong synapses, while synapses of longer-latency or less-effective inputs are weakened.},
  file = {/home/oblivion/Zotero/storage/RSMSTIF9/nn0900_919.html},
  langid = {english},
  number = {9}
}

@book{stallmanFreeSoftwareFree2002,
  title = {Free {{Software}}, {{Free Society}}: {{Selected Essays}} of {{Richard M}}. {{Stallman}}},
  shorttitle = {Free {{Software}}, {{Free Society}}},
  author = {Stallman, Richard},
  year = 2002,
  publisher = {{Lulu.com}},
  abstract = {Essay Collection covering the point where software, law and social justice meet.},
  eprint = {UJlNAgAAQBAJ},
  eprinttype = {googlebooks},
  isbn = {978-1-882114-98-6},
  keywords = {Computers / Social Aspects / General,Law / Intellectual Property / General,Philosophy / Ethics & Moral Philosophy},
  langid = {english},
  pagetotal = {188}
}

@article{starzykMotivationEmbodiedIntelligence2008,
  title = {Motivation in {{Embodied Intelligence}}},
  author = {Starzyk, Janusz A.},
  year = 2008,
  journaltitle = {Frontiers in Robotics, Automation and Control},
  doi = {10.5772/6332},
  abstract = {Open access peer-reviewed chapter},
  file = {/home/oblivion/Zotero/storage/HRL2UJS5/Starzyk - 2008 - Motivation in Embodied Intelligence.pdf;/home/oblivion/Zotero/storage/DB9TT8PG/motivation_in_embodied_intelligence.html},
  langid = {english}
}

@online{SurveyForecastError,
  title = {A Survey of Forecast Error Measures},
  url = {https://www.researchgate.net/publication/281718517_A_survey_of_forecast_error_measures},
  urldate = {2019-06-10},
  abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
  file = {/home/oblivion/Zotero/storage/NZFVQWCH/281718517_A_survey_of_forecast_error_measures.html},
  langid = {english},
  organization = {{ResearchGate}}
}

@online{vinyalsAlphaStarMasteringRealTime2019,
  title = {{{AlphaStar}}: {{Mastering}} the {{Real}}-{{Time Strategy Game StarCraft II}}},
  author = {Vinyals, Oriol and Babuschkin, Igor and Chung, Junyoung and Mathieu, Michael and Silver, David},
  year = 2019,
  url = {https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/}
}

@article{wangCognitiveLogicMathematical,
  title = {Cognitive {{Logic}} versus {{Mathematical Logic}}},
  author = {Wang, Pei},
  keywords = {*}
}

@incollection{wangLogicIntelligence2007,
  title = {The {{Logic}} of {{Intelligence}}},
  booktitle = {Artificial {{General Intelligence}}},
  author = {Wang, Pei},
  editor = {Goertzel, Ben and Pennachin, Cassio},
  year = 2007,
  pages = {31--62},
  publisher = {{Springer Berlin Heidelberg}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-540-68677-4_2},
  abstract = {SummaryIs there an “essence of intelligence” that distinguishes intelligent systems from non-intelligent systems? If there is, then what is it? This chapter suggests an answer to these questions by introducing the ideas behind the NARS (Nonaxiomatic Reasoning System) project. NARS is based on the opinion that the essence of intelligence is the ability to adapt with insufficient knowledge and resources. According to this belief, the author has designed a novel formal logic, and implemented it in a computer system. Such a “logic of intelligence” provides a unified explanation for many cognitive functions of the human mind, and is also concrete enough to guide the actual building of a general purpose “thinking machine”.},
  isbn = {978-3-540-68677-4},
  keywords = {*,Human Mind,Inference Rule,Predicate Logic,Reasoning System,Turing Machine},
  langid = {english},
  series = {Cognitive {{Technologies}}}
}

@article{wangMicroRNABiomarkersDiagnostics2016,
  title = {{{MicroRNA}} as {{Biomarkers}} and {{Diagnostics}}},
  author = {Wang, Jin and Chen, Jinyun and Sen, Subrata},
  year = 2016,
  journaltitle = {Journal of Cellular Physiology},
  volume = {231},
  pages = {25--30},
  issn = {1097-4652},
  doi = {10.1002/jcp.25056},
  abstract = {MicroRNAs (miRNAs) are a group of small non-coding RNAs that are involved in regulating a range of developmental and physiological processes; their dysregulation has been associated with development of diseases including cancer. Circulating miRNAs and exosomal miRNAs have also been proposed as being useful in diagnostics as biomarkers for diseases and different types of cancer. In this review, miRNAs are discussed as biomarkers for cancer and other diseases, including viral infections, nervous system disorders, cardiovascular disorders, and diabetes. We summarize some of the clinical evidence for the use of miRNAs as biomarkers in diagnostics and provide some general perspectives on their use in clinical situations. The analytical challenges in using miRNAs in cancer and disease diagnostics are evaluated and discussed. Validation of specific miRNA signatures as biomarkers is a critical milestone in diagnostics. J. Cell. Physiol. 230: 25–30, 2016. © 2015 Wiley Periodicals, Inc.},
  file = {/home/oblivion/Zotero/storage/2I2TEEQH/Wang et al. - 2016 - MicroRNA as Biomarkers and Diagnostics.pdf;/home/oblivion/Zotero/storage/TJBZP475/jcp.html},
  langid = {english},
  number = {1}
}

@article{wangSelfadaptiveCloudMonitoring2018,
  title = {Self-Adaptive Cloud Monitoring with Online Anomaly Detection},
  author = {Wang, Tao and Xu, Jiwei and Zhang, Wenbo and Gu, Zeyu and Zhong, Hua},
  year = 2018,
  journaltitle = {Future Generation Computer Systems},
  shortjournal = {Future Generation Computer Systems},
  volume = {80},
  pages = {89--101},
  issn = {0167-739X},
  doi = {10.1016/j.future.2017.09.067},
  abstract = {Monitoring is the key to guarantee the reliability of cloud computing systems. By analyzing monitoring data, administrators can understand systems’ statuses to detect, diagnose and solve problems. However, due to the enormous scale and complex structure of cloud computing, a monitoring system should collect, transfer, store and process a large amount of monitoring data, which brings a significant performance overhead and increases the difficulty of analyzing useful information. To address the above issue, this paper proposes a self-adaptive monitoring approach for cloud computing systems. First, we conduct correlation analysis between different metrics, and monitor selected important ones which represent the others and reflect the running status of a system. Second, we characterize the running status with Principal Component Analysis (PCA), estimate the anomaly degree, and predict the possibility of faults. Finally, we dynamically adjust the monitoring period based on the estimated anomaly degree and a reliability model. To evaluate our proposal, we have applied the approach in our open-source TPC-W benchmark Bench4Q deployed in our real cloud computing platform OnceCloud. The experimental results demonstrate that our approach can adapt to dynamic workloads, accurately estimate the anomaly degree, and automatically adjust monitoring periods. Thus, the approach can effectively improve the accuracy and timeliness of anomaly detection in an abnormal status, and efficiently lower the monitoring overhead in a normal status.},
  file = {/home/oblivion/Zotero/storage/2CRYRDJ7/S0167739X1730376X.html},
  keywords = {Adaptive monitoring,Anomaly detection,Cloud computing,Correlation analysis},
  langid = {english}
}

@inproceedings{wangWhatYouMean2008,
  title = {What {{Do You Mean}} by “{{AI}}”?},
  author = {Wang, Pei},
  year = 2008,
  pages = {362--373},
  publisher = {{IOS Press}},
  url = {http://dl.acm.org/citation.cfm?id=1566174.1566207},
  urldate = {2019-05-28},
  eventtitle = {Proceedings of the 2008 Conference on {{Artificial General Intelligence}} 2008: {{Proceedings}} of the {{First AGI Conference}}},
  file = {/home/oblivion/Zotero/storage/VN9XHTE9/citation.html},
  isbn = {978-1-58603-833-5}
}

@report{wangWorkingDefinitionIntelligence1995,
  title = {On the {{Working Definition}} of {{Intelligence}}},
  author = {Wang, Pei},
  year = 1995,
  abstract = {This paper is about the philosophical and methodological foundation of artificial intelligence (AI). After discussing what is a good "working definition", "intelligence" is defined as "the ability for an information processing system to adapt to its environment with insufficient knowledge and resources". Applying the definition to a reasoning system, we get the major components of Non-Axiomatic Reasoning System (NARS),  which is a symbolic logic implemented in a computer system, and has many interesting properties that are closely related to intelligence. The definition also clarifies the difference and relationship between AI and other disciplines, such as computer science. Finally, the definition is compared with other popular definitions of intelligence, and its advantages are argued. 1 To Define Intelligence  1.1 Retrospect  The attempts of clarifying the concept "intelligence" and discussing the possibility and paths to produce it in computing machinery can be backtracked to Turin...},
  file = {/home/oblivion/Zotero/storage/HBZTQYBW/Wang - 1995 - On the Working Definition of Intelligence.pdf;/home/oblivion/Zotero/storage/3T624WBB/summary.html},
  keywords = {**}
}

@inproceedings{wuDataAwareLatentFactor2019,
  title = {A {{Data}}-{{Aware Latent Factor Model}} for {{Web Service QoS Prediction}}},
  booktitle = {{{PAKDD}}},
  author = {Wu, Di and Luo, Xin and Shang, Mingsheng and He, Yi and Wang, Guoyin and Wu, X.},
  year = 2019,
  doi = {10.1007/978-3-030-16148-4_30},
  abstract = {Accurately predicting unknown quality-of-service (QoS) data based on historical QoS records is vital in web service recommendation or selection. Recently, latent factor (LF) model has been widely and successfully applied to QoS prediction because it is accurate and scalable under many circumstances. Hence, state-of-the-art methods in QoS prediction are primarily based on LF. They improve the basic LF-based models by identifying the neighborhoods of QoS data based on some additional geographical information. However, the additional geographical information may be difficult to collect in considering information security, identity privacy, and commercial interests in real-world applications. Besides, they ignore the reliability of QoS data while unreliable ones are often mixed in. To address these issues, this paper proposes a data-aware latent factor (DALF) model to achieve highly accurate QoS prediction, where ‘data-aware’ means DALF can easily implement the predictions according to the characteristics of QoS data. The main idea is to incorporate a density peaks based clustering method into an LF model to discover the neighborhoods and unreliable ones of QoS data. Experimental results on two benchmark real-world web service QoS datasets demonstrate that DALF has better performance than the state-of-the-art models.}
}

@article{xieMultiinputRNAibasedLogic2011,
  title = {Multi-Input {{RNAi}}-Based Logic Circuit for Identification of Specific Cancer Cells},
  author = {Xie, Zhen and Wroblewska, Liliana and Prochazka, Laura and Weiss, Ron and Benenson, Yaakov},
  year = 2011,
  journaltitle = {Science (New York, N.Y.)},
  shortjournal = {Science},
  volume = {333},
  pages = {1307--1311},
  issn = {1095-9203},
  doi = {10.1126/science.1205527},
  abstract = {Engineered biological systems that integrate multi-input sensing, sophisticated information processing, and precisely regulated actuation in living cells could be useful in a variety of applications. For example, anticancer therapies could be engineered to detect and respond to complex cellular conditions in individual cells with high specificity. Here, we show a scalable transcriptional/posttranscriptional synthetic regulatory circuit--a cell-type "classifier"--that senses expression levels of a customizable set of endogenous microRNAs and triggers a cellular response only if the expression levels match a predetermined profile of interest. We demonstrate that a HeLa cancer cell classifier selectively identifies HeLa cells and triggers apoptosis without affecting non-HeLa cell types. This approach also provides a general platform for programmed responses to other complex cell states.},
  eprint = {21885784},
  eprinttype = {pmid},
  file = {/home/oblivion/Zotero/storage/AQPZYQY6/Xie et al. - 2011 - Multi-input RNAi-based logic circuit for identific.pdf},
  keywords = {Apoptosis,bcl-2-Associated X Protein,Biomarkers; Tumor,Cell Line,Gene Expression Regulation; Neoplastic,Gene Regulatory Networks,HeLa Cells,Humans,MicroRNAs,RNA Interference,Synthetic Biology,Transfection},
  langid = {english},
  number = {6047}
}

@inproceedings{xiongApplicationTransferLearning2018,
  title = {Application of {{Transfer Learning}} in {{Continuous Time Series}} for {{Anomaly Detection}} in {{Commercial Aircraft Flight Data}}},
  booktitle = {2018 {{IEEE International Conference}} on {{Smart Cloud}} ({{SmartCloud}})},
  author = {Xiong, P. and Zhu, Y. and Sun, Z. and Cao, Z. and Wang, M. and Zheng, Y. and Hou, J. and Huang, T. and Que, Z.},
  year = 2018,
  pages = {13--18},
  doi = {10.1109/SmartCloud.2018.00011},
  abstract = {In recent years, transfer learning has attracted widespread attention and research. Transfer learning is a new machine learning method that uses existing knowledge to solve different but related domain problems. It relaxes two basic assumptions in traditional machine learning: (1) Training samples for learning and new test samples satisfy the conditions of independent and identical distribution; (2) There must be enough training samples available to learn a good model. Since it is costly and dangerous to repeat testing flights at extreme conditions, building an anomaly detection model for aircraft flight is also constrained by insufficient samples in limited data for different testing flight scenarios. To handle the insufficient samples, we propose a transfer-learning based approach to establishing an anomaly detection model for dangerous actions of aircraft testing flights. In our approach, we transfer the "knowledge" obtained in some testing scenarios to other scenarios containing dangerous action. Evaluation results indicate that our approach works well in terms of convincing accuracy in prediction by models in target scenarios transferred from source scenarios.},
  eventtitle = {2018 {{IEEE International Conference}} on {{Smart Cloud}} ({{SmartCloud}})},
  file = {/home/oblivion/Zotero/storage/QGYMBSXW/8513709.html},
  keywords = {aerospace computing,aircraft,Aircraft,aircraft testing,aircraft testing flights,anomaly detection,Anomaly detection,anomaly detection model,Atmospheric modeling,commercial aircraft flight data,continuous time series,Electronic mail,learning (artificial intelligence),Machine learning,machine learning method,security of data,Task analysis,time series,Training,transfer learning}
}

@article{yanSequenceAnalysisAnomaly2008,
  title = {Sequence {{Analysis}} and {{Anomaly Detection}} of {{Web Service Composition}}},
  author = {Yan, Cairong and Qin, Z. and Shi, Youqun},
  year = 2008,
  journaltitle = {2008 International Conference on Computer Science and Software Engineering},
  doi = {10.1109/CSSE.2008.262},
  abstract = {Traditional security solutions for web services or service composition are access control based models. In this paper, a new approach, sequence analysis based anomaly detection (SABAD) model for service composition is proposed to deal with the insecurity factors. SABAD model includes two parts, one is to mine abnormal service sequence patterns by extracting and analyzing service sequences, the other is to match sequence patterns and find anomaly. In order to integrate with access control policies, the abnormal sequence patterns are made up of static patterns given by system administrator beforehand and dynamic patterns mined by related algorithm. For certain incoming request, a service sequence is extracted firstly, and then matched with the abnormal sequence patterns to determine it safe or unsafe. The experiment results show that SABAD model can not only provide traditional access control but also assure timely anomaly detection and improve the true positive rate of detecting anomalies.}
}

@inproceedings{yuanBioinformaticsApplicationKubeflow2020,
  title = {Bioinformatics {{Application}} with {{Kubeflow}} for {{Batch Processing}} in {{Clouds}}},
  booktitle = {{{ISC Workshops}}},
  author = {Yuan, David and Wildish, Tony},
  year = 2020,
  doi = {10.1007/978-3-030-59851-8_24},
  abstract = {Bioinformatics pipelines make extensive use of HPC batch processing. The rapid growth of data volumes and computational complexity, especially for modern applications such as machine learning algorithms, imposes significant challenges to local HPC facilities. Many attempts have been made to burst HPC batch processing into clouds with virtual machines. They all suffer from some common issues, for example: very high overhead, slow to scale up and slow to scale down, and nearly impossible to be cloud-agnostic. We have successfully deployed and run several pipelines on Kubernetes in OpenStack, Google Cloud Platform and Amazon Web Services. In particular, we use Kubeflow on top of Kubernetes for more sophisticated job scheduling, workflow management, and first class support for machine learning. We choose Kubeflow/Kubernetes to avoid the overhead of provisioning of virtual machines, to achieve rapid scaling with containers, and to be truly cloud-agnostic in all cloud environments. Kubeflow on Kubernetes also creates some new challenges in deployment, data access, performance monitoring, etc. We will discuss the details of these challenges and provide our solutions. We will demonstrate how our solutions work across all three very different clouds for both classical pipelines and new ones for machine learning.},
  file = {/home/oblivion/Zotero/storage/J3C7ARSC/Yuan and Wildish - 2020 - Bioinformatics Application with Kubeflow for Batch.pdf}
}

@inproceedings{yuanBioinformaticsApplicationKubeflow2020a,
  title = {Bioinformatics {{Application}} with {{Kubeflow}} for {{Batch Processing}} in {{Clouds}}},
  booktitle = {High {{Performance Computing}}},
  author = {Yuan, David Yu and Wildish, Tony},
  editor = {Jagode, Heike and Anzt, Hartwig and Juckeland, Guido and Ltaief, Hatem},
  year = 2020,
  pages = {355--367},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-59851-8_24},
  abstract = {Bioinformatics pipelines make extensive use of HPC batch processing. The rapid growth of data volumes and computational complexity, especially for modern applications such as machine learning algorithms, imposes significant challenges to local HPC facilities. Many attempts have been made to burst HPC batch processing into clouds with virtual machines. They all suffer from some common issues, for example: very high overhead, slow to scale up and slow to scale down, and nearly impossible to be cloud-agnostic.We have successfully deployed and run several pipelines on Kubernetes in OpenStack, Google Cloud Platform and Amazon Web Services. In particular, we use Kubeflow on top of Kubernetes for more sophisticated job scheduling, workflow management, and first class support for machine learning. We choose Kubeflow/Kubernetes to avoid the overhead of provisioning of virtual machines, to achieve rapid scaling with containers, and to be truly cloud-agnostic in all cloud environments.Kubeflow on Kubernetes also creates some new challenges in deployment, data access, performance monitoring, etc. We will discuss the details of these challenges and provide our solutions. We will demonstrate how our solutions work across all three very different clouds for both classical pipelines and new ones for machine learning.},
  file = {/home/oblivion/Zotero/storage/B7RZUQZH/Yuan and Wildish - 2020 - Bioinformatics Application with Kubeflow for Batch.pdf},
  isbn = {978-3-030-59851-8},
  keywords = {Amazon Web Services,Clouds,Container orchestration,Data management,Deployment,Google Cloud Platform,Kubeflow,Kubernetes,Monitoring,OpenStack,Workflow},
  langid = {english},
  series = {Lecture {{Notes}} in {{Computer Science}}}
}

@inproceedings{zhouKatibDistributedGeneral2019,
  title = {Katib: {{A Distributed General AutoML Platform}} on {{Kubernetes}}},
  shorttitle = {Katib},
  booktitle = {{{OpML}}},
  author = {Zhou, Jinan and Velichkevich, A. and Prosvirov, Kirill and Garg, A. and Oshima, Yuji and Dutta, D.},
  year = 2019,
  abstract = {Automatic Machine Learning (AutoML) is a powerful mechanism to design and tune models. We present Katib, a scalable Kubernetes-native general AutoML platform that can support a range of AutoML algorithms including both hyperparameter tuning and neural architecture search. The system is divided into separate components, encapsulated as microservices. Each micro-service operates within a Kubernetes pod and communicates with others via well-defined APIs, thus allowing flexible management and scalable deployment at a minimal cost. Together with a powerful user interface, Katib provides a universal platform for researchers as well as enterprises to try, compare and deploy their AutoML algorithms, on any Kubernetes platform.}
}

@inproceedings{zhouKatibDistributedGeneral2019a,
  title = {Katib: {{A Distributed General AutoML Platform}} on {{Kubernetes}}},
  shorttitle = {Katib},
  author = {Zhou, Jinan and Velichkevich, Andrey and Prosvirov, Kirill and Garg, Anubhav and Oshima, Yuji and Dutta, Debo},
  year = 2019,
  pages = {55--57},
  url = {https://www.usenix.org/conference/opml19/presentation/zhou},
  urldate = {2021-04-29},
  eventtitle = {2019 \{\vphantom\}{{USENIX}}\vphantom\{\} {{Conference}} on {{Operational Machine Learning}} ({{OpML}} 19)},
  file = {/home/oblivion/Zotero/storage/2BWXEGQG/Zhou et al. - 2019 - Katib A Distributed General AutoML Platform on Ku.pdf;/home/oblivion/Zotero/storage/UWFNKBGQ/zhou.html},
  isbn = {978-1-939133-00-7},
  langid = {english}
}

@article{zoppiMADneSsMultiLayerAnomaly2021,
  title = {{{MADneSs}}: {{A Multi}}-{{Layer Anomaly Detection Framework}} for {{Complex Dynamic Systems}}},
  shorttitle = {{{MADneSs}}},
  author = {Zoppi, T. and Ceccarelli, A. and Bondavalli, A.},
  year = 2021,
  journaltitle = {IEEE Transactions on Dependable and Secure Computing},
  volume = {18},
  pages = {796--809},
  issn = {1941-0018},
  doi = {10.1109/TDSC.2019.2908366},
  abstract = {Anomaly detection can infer the presence of errors without observing the target services, but detecting variations in the observable parts of the system on which the services reside. This is a promising technique in complex software-intensive systems, because either instrumenting the services’ internals is exceedingly time-consuming, or encapsulation makes them not accessible. Unfortunately, in such systems anomaly detection is often ineffective due to their dynamicity, which implies changes in the services or their expected workload. Here we present our approach to enhance the efficacy of anomaly detection in complex, dynamic software-intensive systems. After discussing the related challenges, we present MADneSs, an anomaly detection framework tailored for the above systems that includes an adaptive multi-layer monitoring module. Monitored data are then processed by the anomaly detector, which adapts its parameters depending on the current system behavior. An anomaly alert is provided if the analysis conducted by the anomaly detector identify unexpected trends in the data. MADneSs is evaluated through an experimental campaign on two service-oriented architectures; software faults are injected in the application layer, and detected through monitoring of underlying system layers. Lastly, we quantitatively and qualitatively discuss our results with respect to state-of-the-art solutions, highlighting the key contributions of MADneSs.},
  eventtitle = {{{IEEE Transactions}} on {{Dependable}} and {{Secure Computing}}},
  file = {/home/oblivion/Zotero/storage/7WG8JRMQ/Zoppi et al. - 2021 - MADneSs A Multi-Layer Anomaly Detection Framework.pdf;/home/oblivion/Zotero/storage/BQXQ6SIZ/8726140.html},
  keywords = {Anomaly detection,Complex systems,context-awareness,Detectors,dynamicity,Heuristic algorithms,MADneSs,Market research,Monitoring,multi-layer,SOA,Software,software-intensive system},
  number = {2}
}

@article{zotero-2,
  type = {article}
}


